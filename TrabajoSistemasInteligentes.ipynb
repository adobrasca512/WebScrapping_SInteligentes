{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc595c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d6d370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Arrow in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Arrow) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.0->Arrow) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#esta es una libreria que me permite manejar fechas, tuve problemas con datetime ya que datetime no reconoce fechas\n",
    "#acortadas en español, mas no palabras como Diciembre, esas si las reconoce.\n",
    "!pip install Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e81595af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement request-html (from versions: none)\n",
      "ERROR: No matching distribution found for request-html\n"
     ]
    }
   ],
   "source": [
    "!pip install request-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a451098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user --install-option=\"--prefix=\" -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682acabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d258b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afea645",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa72f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web scrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#maneja mi archivo json\n",
    "import json\n",
    "#lo uso para remover archivos y no duplicar\n",
    "import os\n",
    "from datetime import datetime\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "import arrow\n",
    "import sys\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "784f4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQuery:\n",
    "    \n",
    "    def __init__(self,sanidad,ciencia):\n",
    "        self.sanidad=sanidad\n",
    "        self.ciencia=ciencia\n",
    "    def getSanidad(self):\n",
    "        return self.sanidad\n",
    "    def getCiencia(self):\n",
    "        return self.ciencia\n",
    "    def lecturaJsonV(self,tema):  \n",
    "        tema_=tema+'.data.json'\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[tema]\n",
    "      #TF-IDF\n",
    "    def lecturaSanidad(self):\n",
    "        tema_=self.sanidad+'.data.json'\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[self.sanidad]\n",
    "    def lecturaCiencia(self):\n",
    "        tema_=self.ciencia,'.data.json'\n",
    "        print(tema_)\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[self.ciencia]\n",
    "    def getNameArticulos(self,json):\n",
    "        articulos=[]\n",
    "        for item in json:\n",
    "            #titulos= item['titulo'] == self.titulo:\n",
    "            articulos.append(item['articulo'])\n",
    "        print(articulos)\n",
    "        return articulos\n",
    "    #con esto unire los nombres de los articulos\n",
    "    #y unire la query a los articulos\n",
    "    def unirArrays(self,a,b):\n",
    "        c=np.append(a,b)\n",
    "        return c\n",
    "    #devuelve un array de articulos\n",
    "    def getAllArticulos(self,json):\n",
    "        arr_articulos=[]\n",
    "        for item in json:\n",
    "            f = open(item, \"r\", encoding=\"utf8\")\n",
    "            leer=str(f.read())\n",
    "            arr_articulos.append(leer.strip('\"\"'))\n",
    "            f.close()\n",
    "        return arr_articulos\n",
    "    #se le pone una lista de documentos mas la query y la query\n",
    "    #devuelve un vector de documentos con la query insertada en tf\n",
    "    #lo utilizo para poder calcular la posicion de la query y ver las frecuencias\n",
    "    #Ejemplo: [[0 1 0 2 3],[0 0 0 1 2]]->frecuencias\n",
    "    def calcularTF(self,documentos,query):\n",
    "        #stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "        stopWords = stopwords.words('spanish')\n",
    "        vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "        vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "        vector_query = vectorizer.transform(query).toarray()\n",
    "        #funcion del coseno se le introducen dos valores \n",
    "        \n",
    "        cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "        i=0\n",
    "        x=0\n",
    "        posicionQuery=0\n",
    "        for vector in vector_documentos:\n",
    "            #print (vector)\n",
    "            for testV in vector_query:\n",
    "                if np.array_equal(vector,testV):\n",
    "                    #print(vector,'y',testV)\n",
    "                    posicionQuery=i\n",
    "                #print (testV)\n",
    "                cosine = cx(vector, testV)\n",
    "                #print (cosine)\n",
    "            i=i+1\n",
    "        return posicionQuery\n",
    "    #Funcion que convierte documentos en vectores y calcula la similitud\n",
    "    #esto facilitara obtener la similitud para poder discriminar mejor \n",
    "    #documentos\n",
    "    def vectorTF_IDF(self,documentos):\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',tokenizer=stemming_tokenizer,use_idf=True,norm='l2')\n",
    "        #tfidf_vectorizer2 = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "        #tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "       # cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        #print (cosine)\n",
    "        return tfidf_matrix\n",
    "    def similitudTF_IDF(self,vector_documento,posicion_query):\n",
    "        cosine = cosine_similarity(vector_documento[posicion_query], vector_documento)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "436a51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    #la data la obtengo de las paginas, es dependiente\n",
    "    def __init__(self,webPage):\n",
    "        self.titulo = []\n",
    "        self.descripcion = ''\n",
    "        self.fecha=[]\n",
    "        self.enlace=[]\n",
    "        self.articulo=[]\n",
    "        self.webPage=webPage\n",
    "        self.etiqueta=[]\n",
    "        self.max=0\n",
    "        self.similitudes=[]\n",
    "        self.other_etiquetas=[]\n",
    "        self.posicionQuery=0\n",
    "    #def __init__(self):\n",
    "        #self.webPage=webPage\n",
    "    #metodo para leer jsons\n",
    "    def lecturaJson(self):\n",
    "        with open(self.webPage.getTema()+'.data.json') as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data\n",
    "     #metodo para leer jsons\n",
    "        \n",
    "    def lecturaJsonV(tema,self):\n",
    "        with open(tema+'.data.json') as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[tema]\n",
    "    #metodo para añadir keys a jsons\n",
    "    #|key=llave del json\n",
    "    #|name=valor de la key\n",
    "    #|posicion=posicion a guardar dentro del json\n",
    "    def add(self,key,name,posicion):\n",
    "        data=self.lecturaJson()\n",
    "        data[self.webPage.getTema()][posicion][key] = name\n",
    "        with open(self.webPage.getTema()+'.data.json', 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "            json_file.close()\n",
    "    #añado la ubicacion del articulo en el json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addTxt(self,name,posicion):\n",
    "        self.add('articulo',name,posicion)\n",
    "    #añado las etiquetas al json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addEtiqueta(self,etiqueta,posicion):\n",
    "        self.add('etiquetas',etiqueta,posicion)\n",
    "    #añado la fecha al json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addFecha(self,fecha,posicion):\n",
    "        self.add('fecha',fecha,posicion)\n",
    "    #aqui limpio la fecha del articulo para que se vea 05-12-2021 asi\n",
    "    #|date=fecha string\n",
    "    def setDate(self,date):\n",
    "        date1=date.strip('UTC')\n",
    "        fdate = date1.split('-', 1)[0]\n",
    "        fecha = arrow.get(fdate, 'DD MMM YYYY',locale='ES')\n",
    "        d=str(fecha)\n",
    "        fecha_ = d.split('T', 1)[0]\n",
    "        return fecha_\n",
    "    #metodo para extraer valores del json con sus keys\n",
    "    #|value=array para añadir los items a un array\n",
    "    #|nombre=la key del json\n",
    "    def get(self,value,nombre):\n",
    "        #aqui saco todos los titulos\n",
    "        data=self.lecturaJson()\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            value.append(item[nombre])\n",
    "        return value\n",
    "    #metodo para obtener TODOS los titulos dentro del json\n",
    "    def getTitulo(self):\n",
    "        arr=[]\n",
    "        return self.get(arr,'titulo')\n",
    "    #metodo para obtener TODAS fecha en el segundo link y guardarlo en el json\n",
    "    def getFecha(self):\n",
    "        i=0\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('div', class_='a_md_f')\n",
    "            if elements:\n",
    "                for item in elements:\n",
    "                    if item.select('time'):\n",
    "                        self.fecha.append(self.setDate(self.webPage.parseo(item.select('time'))))\n",
    "                        self.addFecha(self.fecha[i],i)\n",
    "                    else:\n",
    "                        print('no tiene time')\n",
    "            else: \n",
    "                #despues de tanta vaina voy a eliminar los que no siguen el patron que yo tengo\n",
    "               #caso excepcional para TECNOLOGIA ya que contiene articulos que son ads pero tambien forman parte de los articulos\n",
    "                #elements=noticia.find_all('div', class_='a_pt | uppercase color_gray_medium_lighter')\n",
    "                #for item in elements:\n",
    "                self.fecha.append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                self.addFecha(self.fecha[i],i)\n",
    "            i=i+1\n",
    "        return self.fecha\n",
    "    #metodo para obtener el enlace dentro del json\n",
    "    def getEnlace(self):\n",
    "        #aqui saco todos los titulos\n",
    "        self.enlace=[]\n",
    "        return self.get(self.enlace,'enlace')\n",
    "    #metodo para obtener el articulo dentro del json\n",
    "    def getArticulo(self):\n",
    "        i=0\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('div', class_='a_c clearfix')\n",
    "            if elements:    \n",
    "                for item in elements:\n",
    "                    self.articulo.append(str(self.webPage.parseo(item.select('p'))))\n",
    "            else:\n",
    "                print('no encontrado, FALTA ARTICULO')\n",
    "             #caso excepcional para TECNOLOGIA ya que contiene articulos que son ads pero tambien forman parte de los articulos\n",
    "                #elements=noticia.find_all('div',class_='a_b article_body | color_gray_dark initial_letter especial a_b__e col desktop_8 tablet_8 mobile_4 margin_center')\n",
    "                #for item in elements:\n",
    "                self.articulo.append('Debido a que no es compatible con el Scrapper no se puede mostrar este articulo')\n",
    "            i=i+1\n",
    "        return self.articulo\n",
    "    #metodo obtengo la etiqueda de TODAS las paginas.\n",
    "    def getEtiqueta(self):\n",
    "        i=0\n",
    "        arr_etiquetas=[]\n",
    "        self.etiqueta=[]\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('ul', class_='_df _ls')\n",
    "            for item in elements:\n",
    "                e=self.webPage.parseo(item.select('li'))\n",
    "                arr_etiquetas=e.split(',')\n",
    "                self.etiqueta.append(arr_etiquetas)\n",
    "            self.addEtiqueta(arr_etiquetas,i)\n",
    "            i=i+1\n",
    "            self.other_etiquetas=self.etiqueta\n",
    "        return self.etiqueta\n",
    "    #metodo para guardar el articulo en un TXT\n",
    "    def saveArticle(self):\n",
    "        i=0\n",
    "        #emparejamos titulo y articulo\n",
    "        self.titulo=self.getTitulo()\n",
    "        self.articulo=self.getArticulo()\n",
    "        self.fecha=self.getFecha() \n",
    "        print('TITULO')\n",
    "        print(len(self.titulo))\n",
    "        print('ARTICULO')\n",
    "        print(len(self.articulo))\n",
    "        print('FECHAS')\n",
    "        print(len(self.fecha))\n",
    "        for articulo, titulo,fecha in zip(self.articulo, self.titulo,self.fecha): #obtenemos los valores en cada iteración\n",
    "            parrafo=titulo+'\\n'+articulo\n",
    "            parrafo_=parrafo.strip(\"[]\")\n",
    "            tema=self.webPage.getTema()\n",
    "            nombre=tema+'.'+fecha+'.'+str(i)+'.txt'\n",
    "            self.addTxt(nombre,i)\n",
    "            self.webPage.escrituraTexto(parrafo_,nombre)\n",
    "            i=i+1   \n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|titulo=titulo del articulo\n",
    "    def setTitulo(self,titulo):\n",
    "        self.titulo=titulo\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|descripcion=descripcion del articulo\n",
    "    def setDescripcion(self,descripcion):\n",
    "        self.descripcion=descripcion\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|fecha=fecha del articulo\n",
    "    def setFecha(self,fecha):\n",
    "        self.fecha=fecha\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|enlace=enlace del articulo\n",
    "    def setEnlace(self,enlace):\n",
    "        self.enlace=enlace\n",
    "    #obtenemos la descripcion (borrar no se usa)\n",
    "    def getDescripcion(self):\n",
    "        print(self.descripcion)\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|etiqueta=etiqueta del articulo\n",
    "    def setEtiqueta(self,etiqueta):\n",
    "        self.etiqueta=etiqueta\n",
    "    #setea el valor del top\n",
    "    #|maxi=top de articulos\n",
    "    def setMax(self,maxi):\n",
    "        self.max=maxi\n",
    "    #aqui leemos exclusivamente un txt\n",
    "    #|nombre=nombre del articulo\n",
    "    def lecturaTxt(self,nombre):\n",
    "        f = open(nombre, \"r\", encoding=\"utf8\")\n",
    "        texto=f.read()\n",
    "        f.close()\n",
    "        return texto\n",
    "    #este metodo es para obtener un elemento por su key \n",
    "    #|key=llave del json\n",
    "    def getX(self,key):\n",
    "        #leo el json\n",
    "        value=[]\n",
    "        data=self.lecturaJson()\n",
    "        #recorro el json y busco su txt\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            #verificamos si la posicion esta en el top\n",
    "            value.append(item[key])\n",
    "            #self.similitudes=value\n",
    "            # me devuelve un array de txt\n",
    "        return value\n",
    "    #metodo para mostrar las noticias en el top\n",
    "    #|posicion_noticia= es la posicion de la noticia a obtener\n",
    "    def getSimilitud_Paginas(self,posicion_noticia):\n",
    "        pag_similitud=[]\n",
    "        articulo=''\n",
    "        #cargamos el array de textos [texto1.txt,texto2.txt,texto3.txt] hasta la posicion top\n",
    "        articulos=self.getX('articulo')\n",
    "        #cuando se seleccione el boton me dira que noticia es: la 1, la 2,etc \n",
    "        #leo el texto en la posicion estipulada\n",
    "        #verifico que el valor sea menor que el maximo\n",
    "        articulo=self.lecturaTxt(articulos[posicion_noticia])\n",
    "        #hacemos match con las similitudes\n",
    "        return articulo\n",
    "    #TF-IDF\n",
    "    def getNameArticulos(json,self):\n",
    "        articulos=[]\n",
    "        for item in json:\n",
    "            #titulos= item['titulo'] == self.titulo:\n",
    "            articulos.append(item['articulo'])\n",
    "        return articulos\n",
    "    #con esto unire los nombres de los articulos\n",
    "    #y unire la query a los articulos\n",
    "    def unirArrays(a,b,self):\n",
    "        c=np.append(a,b)\n",
    "        return c\n",
    "    #devuelve un array de articulos\n",
    "    def getAllArticulos(json,self):\n",
    "        arr_articulos=[]\n",
    "        for item in json:\n",
    "            f = open(item, \"r\", encoding=\"utf8\")\n",
    "            leer=str(f.read())\n",
    "            arr_articulos.append(leer.strip('\"\"'))\n",
    "            f.close()\n",
    "        return arr_articulos\n",
    "    #se le pone una lista de documentos mas la query y la query\n",
    "    #devuelve un vector de documentos con la query insertada en tf\n",
    "    #lo utilizo para poder calcular la posicion de la query y ver las frecuencias\n",
    "    #Ejemplo: [[0 1 0 2 3],[0 0 0 1 2]]->frecuencias\n",
    "    def calcularTF(documentos,query,self):\n",
    "        #stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "        stopWords = stopwords.words('spanish')\n",
    "        vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "        vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "        vector_query = vectorizer.transform(query).toarray()\n",
    "        #funcion del coseno se le introducen dos valores \n",
    "        \n",
    "        cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "        i=0\n",
    "        x=0\n",
    "        posicionQuery=0\n",
    "        for vector in vector_documentos:\n",
    "            print (vector)\n",
    "            for testV in vector_query:\n",
    "                if np.array_equal(vector,testV):\n",
    "                    print(vector,'y',testV)\n",
    "                    posicionQuery=i\n",
    "                print (testV)\n",
    "                cosine = cx(vector, testV)\n",
    "                print (cosine)\n",
    "            i=i+1\n",
    "        return posicionQuery\n",
    "    #Funcion que convierte documentos en vectores y calcula la similitud\n",
    "    #esto facilitara obtener la similitud para poder discriminar mejor \n",
    "    #documentos\n",
    "    def vectorTF_IDF(documentos,self):\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        #tfidf_vectorizer2 = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "        #tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "       # cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        #print (cosine)\n",
    "        return tfidf_matrix\n",
    "    def similitudTF_IDF(vector_documento,posicion_query,self):\n",
    "        cosine = cosine_similarity(vector_documento[posicion_query], vector_documento)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        return cosine\n",
    "    def mostrarArticulo(self):\n",
    "        texto=''\n",
    "        \n",
    "        #consultamos en el json el nombre del txt\n",
    "        data=self.lecturaJson()\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            if item['titulo'] == self.titulo:\n",
    "                texto=item['articulo']\n",
    "        #abrimos el txt y lo leemos\n",
    "        f = open(texto, \"r\", encoding=\"utf8\")\n",
    "        self.articulo=str(f.read())\n",
    "        a=self.articulo.strip('\"\"')\n",
    "        self.articulo=a\n",
    "        f.close()\n",
    "        return self.articulo\n",
    "    #estos son los calculos de la similitud\n",
    "    #|match=match del array1 con array2\n",
    "    #ejemplo: [a,b,c]U[d,c,r]=c 1 match\n",
    "    #|e1=es el array que escogio el usuario\n",
    "    #|array2= son los otros arrays top\n",
    "    def calculos(self,e1,array2,match):\n",
    "       # print('match encontrados',match)\n",
    "        #print('formula',str(2),'*',str(match),'/',str((len(e1))),'+',str(len(array2)))\n",
    "        formula=(2*match)/((len(e1))+(len(array2)))\n",
    "        return formula\n",
    "    #metodo para rankear la lista, devuelve una lista de las nuevas posiciones de los elementos\n",
    "    #|li=es el array de similitudes\n",
    "    def integers(self,li):\n",
    "        arr=[]\n",
    "        for i in range(len(li)):\n",
    "            arr.append(i)\n",
    "        return arr\n",
    "    def sorting(self,li):\n",
    "        arr=self.integers(li)\n",
    "        for i in range(len(li)):\n",
    "            for j in range(len(li)):\n",
    "                if li[i] > li[j]:\n",
    "                    li[j],li[i] = li[i],li[j]\n",
    "                    arr[j],arr[i] = arr[i],arr[j]\n",
    "        self.similitudes=self.solo_Top(li)\n",
    "        arr_=[]\n",
    "        arr_=self.solo_Top(arr)\n",
    "        return arr_\n",
    "    #esto lo hago solo por si acaso en las similitudes tengo algo ejemplo:\n",
    "    #[covid-19 enfermedad, covid]U[covid-19, covid] para que no diga que son totalmente iguales o algo asi.\n",
    "    def eliminarEspacios(self,arr):\n",
    "        new_arr=[]\n",
    "        for item in arr:\n",
    "            a_string=str(item)\n",
    "            a=a_string.replace(\" \", \"\")\n",
    "            new_arr.append(a)\n",
    "        return new_arr\n",
    "     #aqui rompo el array y saco solo el top\n",
    "    #|arr=array recortado\n",
    "    def solo_Top(self,arr):\n",
    "        new_arr=[]\n",
    "        i=0\n",
    "        maxi=self.max\n",
    "        for item in arr:\n",
    "            if i<maxi:\n",
    "                new_arr.append(item)\n",
    "            else:\n",
    "                break\n",
    "            i=i+1\n",
    "        return new_arr\n",
    "    #aqui obtengo las similitudes entr etiquetas\n",
    "    #|e1= es el array que escogio el usuario\n",
    "    def similitud(self,e2):\n",
    "        n_noticia=0\n",
    "        #contador de similitudes\n",
    "        contador_match=0\n",
    "        maximo=self.max\n",
    "        i=0\n",
    "        e1=self.etiqueta\n",
    "        e1_=self.eliminarEspacios(e1)\n",
    "        #print(self.etiqueta)\n",
    "        resultados=[]\n",
    "        #aqui sera en el array simple ['comida','perro','gato']\n",
    "        for array2 in e2:\n",
    "            contador_match=0\n",
    "        #solo obtendre las similitudes de los top\n",
    "            array2_=self.eliminarEspacios(array2)\n",
    "            #[['comida','perro','avispa'],['azul','perro','can']]  \n",
    "            for item in array2_:\n",
    "                #print('entrando en el bucle')\n",
    "                ##print(item)\n",
    "                for array1 in e1_:\n",
    "                    #print('_______________________________________')\n",
    "                    #print(item,'es igual a',array1)\n",
    "                    if str(array1) == str(item):\n",
    "                        contador_match=contador_match+1\n",
    "                        #print(item,'SI igual a',array1)\n",
    "                        #print()\n",
    "                        #print('array encontrado similitud:',array2_)          \n",
    "                    resultado=self.calculos(e1_,array2_,contador_match)\n",
    "                    #print('la similitud total es de:',resultado)\n",
    "                    resultado_=resultado*100\n",
    "                #añadimos el resultado en un array de similitudes\n",
    "            i=i+1\n",
    "            \n",
    "            resultados.append(resultado_)\n",
    "            #print(array2)\n",
    "            #print('grado de similitud con array1',str(resultado_)+'%')\n",
    "            #print('_______________________________________')\n",
    "        arr_final=[]\n",
    "        arr_final=self.sorting(resultados)\n",
    "        return arr_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8e0348d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Usuario():\n",
    "    def __init__(self, titulo, categoria,top,data):\n",
    "        self.titulo = titulo\n",
    "        self.categoria = categoria\n",
    "        self.data = data\n",
    "        self.top=top\n",
    "    #seteamos los campos de datos para que nos muestre los necesarios nada mas\n",
    "    def cargarSeleccion(self):\n",
    "        data=self.data.lecturaJson()\n",
    "        #print('categoria es',self.categoria)\n",
    "        for item in data[self.categoria]:\n",
    "            #validamos que la seccion seleccionada este en el json\n",
    "            if self.titulo  in item['titulo']:\n",
    "                self.data.setEnlace(item[\"enlace\"]) \n",
    "                self.data.setTitulo(item[\"titulo\"])\n",
    "                self.data.setDescripcion(item[\"descripcion\"]) \n",
    "                self.data.setFecha(item[\"fecha\"])\n",
    "                self.data.setEtiqueta(item[\"etiquetas\"])\n",
    "                self.data.setMax(self.top)\n",
    "    def setTop(self,top):\n",
    "        self.top=top\n",
    "        self.data.setMax(self.top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6157ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WebPages():\n",
    "    def __init__(self, tema, url):\n",
    "        self.tema = tema\n",
    "        self.url = url\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "   \n",
    "    def getRequest(self,url):\n",
    "        request = requests.get(url, headers=self.headers)\n",
    "        html = request.content.decode(\"utf-8\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    #metodo que escribe un archivo\n",
    "    #|texto=lo que quieras introducir en el archivo\n",
    "    #|nombre=nombre del archivo \n",
    "    def escritura(self,texto,nombre):\n",
    "        #si existe un path con este nombre lo quitaremos, evita duplicados\n",
    "        if os.path.exists(nombre):\n",
    "            os.remove(nombre)\n",
    "            #print('este path existe, lo eliminaremos')\n",
    "        with open(nombre, 'w') as f:\n",
    "            json.dump(texto, f)\n",
    "            f.close()\n",
    "    def escrituraTexto(self,texto,nombre):\n",
    "        #si existe un path con este nombre lo quitaremos, evita duplicados\n",
    "        if os.path.exists(nombre):\n",
    "            os.remove(nombre)\n",
    "            #print('este path existe, lo eliminaremos')\n",
    "        file= open(nombre, 'w', encoding='utf-8')\n",
    "        file.write(texto)\n",
    "        file.close()\n",
    "    #parseo: se encarga de pasar el fragmento html a texto\n",
    "    #|fragmento=pedazo de html ejemplo=<a>...</a> \n",
    "    def parseo(self,fragmento):\n",
    "    #vuelvo string el fragmento html\n",
    "        word=str(fragmento)\n",
    "    #remueve los brackets\n",
    "        parsedword=word.strip(\"[]\")\n",
    "    #obtengo el texto dentro del html, en caso de que halla texto contenido\n",
    "        soup1=BeautifulSoup(parsedword, from_encoding='utf-8').get_text()\n",
    "        return soup1\n",
    "    #inicia el scrappeo a los primeros links\n",
    "    def miPais_news_scraper(self):\n",
    "        article_list={}\n",
    "        article_list[self.tema]=[]\n",
    "        soup=self.getRequest(self.url)\n",
    "    \n",
    "    # Encontramos todos los articulos necesarios\n",
    "        elements=soup.find_all('article', class_='c')\n",
    "    #de todos los articulos iremos revisando item x item.\n",
    "        for item in elements:\n",
    "            #aqui es donde tomo los enlaces,titulos,entradillas, fechas y las introduzco en un json\n",
    "            enlace='https://elpais.com'+item.a['href']\n",
    "            article_list[self.tema].append({'titulo':self.parseo(item.select('header h2 a')),'enlace':enlace,'descripcion':self.parseo(item.select('p'),),\n",
    "                                            'fecha':\"\",'articulo':'','etiquetas':[]} )\n",
    "            \n",
    "        return article_list   \n",
    "        \n",
    "    #obtengo el tema;sanidad,tecnologia,ciencia.\n",
    "    def getTema(self):\n",
    "        return self.tema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by Adilem Dobras\n",
    "#sanidad\n",
    "if __name__ == '__main__':\n",
    "    sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "    sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "    #ciencia\n",
    "    ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "    ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "    data_sanidad=Data(sanidad)\n",
    "    data_sanidad.saveArticle() \n",
    "    #data_sanidad.string('Hola.:')\n",
    "    data_ciencia=Data(ciencia)\n",
    "    data_ciencia.saveArticle()    \n",
    "    #data_sanidad.getEtiqueta()\n",
    "           \n",
    "    #data_ciencia.getEtiqueta()\n",
    "    tf_idf=DataQuery('sanidad','ciencia')\n",
    "    #print(tf_idf.getCiencia())\n",
    "    #abro el json\n",
    "    json_sanidad=tf_idf.lecturaJsonV('sanidad')\n",
    "    #saco las direcciones de los articulos\n",
    "    #print(json_sanidad)\n",
    "    articulos_sanidad=tf_idf.getNameArticulos(json_sanidad)\n",
    "    #abro el json\n",
    "    json_ciencia=tf_idf.lecturaJsonV('ciencia')\n",
    "    #saco las direcciones de los articulos \n",
    "    articulos_ciencia=tf_idf.getNameArticulos(json_ciencia)\n",
    "    #inserto todas las direcciones en un array\n",
    "    articulos=tf_idf.unirArrays(articulos_sanidad,articulos_ciencia)\n",
    "    print(articulos)\n",
    "    #consigo el array de documentos\n",
    "    array_documentos=tf_idf.getAllArticulos(articulos)\n",
    "    #consulto la query al usuario y la inserto en el array de documentos\n",
    "    array_query=['Eso plantea problemas desde el punto de vista tecnológico, porque cuando se utilizan como ingrediente en ciertos productos, como palmeras de chocolate, empanadas, cruasanes, etc., las características organolépticas se ven perjudicadas: se derriten a temperatura ambiente, aportan un aspecto poco apetecible, tienen una textura menos agradable, etc., Para tratar de solucionar esos inconvenientes sin tener que abandonar el uso de aceites vegetales, se echó mano de un proceso que se conoce como hidrogenación, que, dicho mal y pronto, consiste en añadir átomos de hidrógeno a los ácidos grasos de los aceites para cambiar su estructura, de manera que pasan de ser insaturados (y líquidos a temperatura ambiente) a ser un poco más saturados (y un poco más sólidos). De este modo se consigue que los aceites sean algo más sólidos de lo habitual, así que son más estables, se enrancian con menos facilidad y aportan a los productos unas mejores características, sobre todo de aspecto y textura., Así es como se obtienen las famosas grasas hidrogenadas. El problema es que ese proceso puede dar lugar a la formación de los dichosos ácidos grasos trans, que durante muchos años ostentaron el título de enemigo público número uno. Había motivos justificados para ello, porque hoy sabemos a ciencia cierta que su consumo aumenta el riesgo de sufrir enfermedades cardiovasculares. Por esta razón las autoridades sanitarias coinciden en que es necesario reducir su consumo o eliminarlos totalmente de la dieta. Esto, sumado a la preocupación social, llevó a muchos fabricantes a buscar alternativas para evitar la presencia de estas grasas trans en los alimentos., Una de las soluciones consistió en mejorar los procesos con los que se obtienen esas grasas vegetales más sólidas. Hoy en día la presencia de grasas hidrogenadas en la lista de ingredientes de un producto ya no implica necesariamente que contenga grasas trans., Editorial: Ediciones Destino, Colección: Imago Mundi, Número de páginas: 376, Precio: 17,90€, De todos modos, como consumidores no tenemos forma de conocer la cantidad de grasas trans que contiene un producto, porque esa información no se muestra en la etiqueta, a diferencia de lo que ocurre en países como Estados Unidos donde es obligatorio. De hecho, en el momento de escribir este libro ni siquiera están definidos en la legislación europea unos límites máximos para el contenido de estos productos en los alimentos. Estaba previsto para 2014, pero se anunció su retraso hasta 2021 (a partir del 1 de abril de este año entra en vigor un límite europeo para esas grasas trans de origen industrial). Esa regulación sí existe en algunos países europeos, como Dinamarca, donde los alimentos no pueden contener más de un 2% de grasas trans por cada 100 gramos de grasa. En España seguimos esperando. Por el momento lo que sabemos es que, según un estudio publicado por el Ministerio de Sanidad en el año 2015, el contenido medio de estas grasas en los alimentos era inferior al 2% con respecto a la grasa total, es decir, la cantidad no es muy elevada, pero sería deseable que fuera incluso menor., Las grasas hidrogenadas y las grasas trans ya no reciben tanta atención como antes, y es sobre todo porque cada vez se utilizan menos en la industria alimentaria debido a su mala fama. En su lugar, comenzaron a utilizarse otras opciones. La más inmediata fue el aceite de palma, que en poco tiempo se hizo omnipresente en la mayoría de los alimentos ultraprocesados, debido principalmente a su bajo coste y sus características tecnológicas. Se trata de un aceite que tiene una alta proporción de ácidos grasos saturados, así que aporta a los productos una buena textura y un aspecto adecuado, que se mantienen a lo largo del tiempo., El aceite de palma no cayó del cielo de repente, pero lo pareció. Ya se utilizaba en la formulación de muchos productos desde tiempo atrás, pero no éramos conscientes de ello porque se declaraba en la lista de ingredientes como “grasa vegetal”. Esto cambió a finales del año 2014, cuando entró en vigor el reglamento europeo que obliga a especificar el nombre de cada una de las grasas que contiene un producto, en lugar de declararlas de forma genérica. A partir de entonces comenzamos a encontrar el aceite de palma hasta en la sopa... Literalmente., La historia se repitió. En poco tiempo este aceite adquirió muy mala fama. Fue debido sobre todo a dos motivos. Por un lado, se habló mucho y mal de la forma en la que se obtiene la materia prima, que procede principalmente de Indonesia y Malasia, donde su explotación supone un enorme impacto ambiental y se realiza en unas condiciones laborales que dejan bastante que desear., Por otro, en un breve espacio de tiempo se sucedieron varias publicaciones que alertaban de los posibles efectos de este aceite sobre la salud. Entre ellas, un informe de la Autoridad Europea de Seguridad Alimentaria (EFSA) que advertía de la presencia de compuestos tóxicos en el aceite de palma, derivados del calentamiento que se aplica en el proceso de obtención., También se publicaron estudios que relacionaban uno de los componentes del aceite de palma con efectos adversos sobre la salud. Se trata del ácido palmítico, que precisamente recibe ese nombre porque es abundante en este tipo de aceite (se encuentra en una proporción del 43 % aproximadamente). De todos modos, no está claro que este ácido graso sea tan malo como a veces se pinta. Además, es uno de los más comunes y está presente de forma natural en infinidad de alimentos, como el aceite de oliva o la leche., La conclusión que podemos extraer de todo esto es que el aceite de palma no es el más recomendable, especialmente en un entorno donde tenemos un aceite mucho más saludable, como el de oliva. Pero eso no significa que sea tóxico o venenoso, como llegó a publicar algún medio de comunicación. Lo cierto es que no está claro que su consumo tenga un efecto perjudicial sobre la salud, o al menos no tanto como muchas personas piensan. En cualquier caso, nuestra atención en este aspecto no debería centrarse tanto sobre el aceite de palma y sus características, sino más bien sobre los productos en los que se encuentra: galletas, pizzas, cruasanes, dónuts, etc., Después de la preocupación social que generó el aceite de palma en España entre los años 2016 y 2017, muchas empresas comenzaron a sustituirlo por otros tipos de grasa, como el aceite de coco, y a destacar en el envase la ausencia del temido ingrediente. En estos casos también deberíamos aplicar la máxima de fijarnos en el conjunto del alimento en lugar de centrarnos en un ingrediente aislado., Miguel A. Lurueña (@gominolasdpetro) es doctor, licenciado en ciencia y tecnología de los alimentos, ingeniero técnico agroalimentario y divulgador científico (www.gominolasdepetroleo.com)., NUTRIR CON CIENCIA es una sección sobre alimentación basada en evidencias científicas y en el conocimiento contrastado por especialistas. Comer es mucho más que un placer y una necesidad: la dieta y los hábitos alimenticios son ahora mismo el factor de salud pública que más puede ayudarnos a prevenir numerosas enfermedades, desde muchos tipos de cáncer hasta la diabetes. Un equipo de dietistas-nutricionistas nos ayudará a conocer mejor la importancia de la alimentación y a derribar, gracias a la ciencia, los mitos que nos llevan a comer mal., Puedes seguir a Materia en Facebook, Twitter, Instagram o suscribirte aquí a nuestra newsletter']\n",
    "    array_documentos_query=tf_idf.unirArrays(array_query,array_documentos)\n",
    "    print(array_documentos_query)\n",
    "    #busco la posicion de mi query\n",
    "    posicion_query=tf_idf.calcularTF(array_documentos_query,array_query)\n",
    "    #obtengo el vector de documentos\n",
    "    vector_documentos=tf_idf.vectorTF_IDF(array_documentos_query)\n",
    "    #obtengo la similitud\n",
    "    similitud=tf_idf.similitudTF_IDF(vector_documentos,posicion_query)\n",
    "    print(similitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644f876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no encontrado, FALTA ARTICULO\n",
      "TITULO\n",
      "27\n",
      "ARTICULO\n",
      "27\n",
      "FECHAS\n",
      "27\n",
      "TITULO\n",
      "40\n",
      "ARTICULO\n",
      "40\n",
      "FECHAS\n",
      "40\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "TITULO\n",
      "30\n",
      "ARTICULO\n",
      "30\n",
      "FECHAS\n",
      "30\n",
      "['Cataluña bate récord de visitas por covid a ambulatorios con 73.000 en un día', 'Víctimas del mar, la pobreza y el olvido', 'La baja de casi 2.500 profesionales sanitarios tensiona aún más el sistema en Cataluña', 'El debate sobre las cuarentenas en los colegios: ¿Hay que confinar a toda la clase tras un positivo? ', 'La variante Paz Padilla ', 'El sistema inmune de vacunados y reinfectados resiste ante ómicron ', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'Los contagiados en la Comunidad Valenciana crecen en 32.659 casos en una semana pero solo hay cinco más en las UCI', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', 'Cataluña habilita las farmacias para comunicar los positivos por covid para reducir presión en los ambulatorios', 'La avalancha de contagios por la variante ómicron y el avance de la tercera dosis disparan la inmunidad entre la población', 'Ómicron lleva al límite a la atención primaria', 'Destellos de felicidad', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'El año por delante', 'Cataluña y Madrid acumulan miles de contagios sin notificar a Sanidad', 'Las zonas con mayor poder adquisitivo de Madrid sufren mayor tasa de contagios de covid', 'A ver si se acaba 2020 otra vez', 'Colas para recoger los test de antígenos gratuitos en Torrejón de Ardoz y Móstoles', 'Paremos la pandemia del lucro', 'La imparable ola de contagios de la ola ómicron obliga al Gobierno a dar un giro en la gestión de la pandemia', 'El impacto de la sexta ola de covid en Cataluña: “No hay policías para Nochevieja, caemos como moscas”', 'Los antígenos de la especulación', 'Una Chevrolet 400, Marco Polo y una rifa, al auxilio de la Navidad de Juan Manuel', 'Ayuso, en su balance anual: “Madrid tiene la mejor sanidad de España”', 'La hidrocefalia pediátrica o cómo la falta de servicios de salud esenciales marca una vida', 'Navidad jubilosa']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['Cataluña bate récord de visitas por covid a ambulatorios con 73.000 en un día', 'Víctimas del mar, la pobreza y el olvido', 'La baja de casi 2.500 profesionales sanitarios tensiona aún más el sistema en Cataluña', 'El debate sobre las cuarentenas en los colegios: ¿Hay que confinar a toda la clase tras un positivo? ', 'La variante Paz Padilla ', 'El sistema inmune de vacunados y reinfectados resiste ante ómicron ', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'Los contagiados en la Comunidad Valenciana crecen en 32.659 casos en una semana pero solo hay cinco más en las UCI', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', 'Cataluña habilita las farmacias para comunicar los positivos por covid para reducir presión en los ambulatorios', 'La avalancha de contagios por la variante ómicron y el avance de la tercera dosis disparan la inmunidad entre la población', 'Ómicron lleva al límite a la atención primaria', 'Destellos de felicidad', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'El año por delante', 'Cataluña y Madrid acumulan miles de contagios sin notificar a Sanidad', 'Las zonas con mayor poder adquisitivo de Madrid sufren mayor tasa de contagios de covid', 'A ver si se acaba 2020 otra vez', 'Colas para recoger los test de antígenos gratuitos en Torrejón de Ardoz y Móstoles', 'Paremos la pandemia del lucro', 'La imparable ola de contagios de la ola ómicron obliga al Gobierno a dar un giro en la gestión de la pandemia', 'El impacto de la sexta ola de covid en Cataluña: “No hay policías para Nochevieja, caemos como moscas”', 'Los antígenos de la especulación', 'Una Chevrolet 400, Marco Polo y una rifa, al auxilio de la Navidad de Juan Manuel', 'Ayuso, en su balance anual: “Madrid tiene la mejor sanidad de España”', 'La hidrocefalia pediátrica o cómo la falta de servicios de salud esenciales marca una vida', 'Navidad jubilosa']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante ómicron ', '¿Qué diámetro tiene el universo?', 'El oro: una historia de violencia cósmica', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', '¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La ‘flurona’ no es nueva: le han puesto nombre ahora, pero ya se observó en España al inicio de la pandemia', '¿Por qué nos obsesiona Marte?', '¿Por qué recordamos lo que ocurrió hace mucho tiempo y olvidamos lo que pasó ayer?', 'Ómicron es el virus con la propagación más rápida de la historia', '“España tendría que vacunar a su sistema de salud, fortalecerlo para la fase endémica”', 'Las organizaciones investigadoras que soliciten financiación europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimización', 'Más mascarillas, clases semipresenciales y test continuos: ómicron altera la vuelta a las clases en todo el mundo', 'No será Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase será presencial: Educación reclamará a las comunidades más “tensión” en la aplicación del protocolo anticovid', '¿Cómo se mide la altura de las montañas?', 'El oro: una historia de violencia cósmica', 'Jacques Tits, una vida consagrada al edificio de las matemáticas', 'Cómo el ataque de Pearl Harbor cambió la estadística de las pruebas diagnósticas', 'La teoría cuántica es más coherente de lo que creíamos', 'Las matemáticas de las máquinas morales', 'Los renos de Papá Noel', 'Teselaciones posibles e imposibles', 'Sin líneas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que ‘cegaron’ a Ramón y Cajal y Valle-Inclán', 'Los relatos médicos de un poeta', 'La realidad completándose a sí misma', '¿Qué diámetro tiene el universo?', '¿Cómo se mide la altura de las montañas?', 'Como el fuego es un plasma, ¿podría usarse plasma de agua para apagarlo?', '¿Cuánto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muérdago y otras plagas que evitar durante las fiestas', 'Las ‘apps’ nutricionales o cómo comer bien no debería depender de uno mismo', 'Malnutrición invisible: el impacto de la pobreza en la salud infantil', 'El óxido de etileno, la sustancia cancerígena que ha obligado a retirar miles de alimentos en la UE', 'Que no te líen con los ingredientes: aceites y grasas de mala calidad nutricional']\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "class R_Noticias(ttk.Frame):\n",
    "    \n",
    "    def __init__(self, main_window,sanidad,tecnologia,ciencia):\n",
    "        super().__init__(main_window)\n",
    "        self.grid()\n",
    "        #self.usuario= Usuario.__new__(Usuario)\n",
    "        self.create_widgets()\n",
    "        self.sanidad=sanidad\n",
    "        self.tecnologia=tecnologia\n",
    "        self.ciencia=ciencia\n",
    "        self.sort=[]\n",
    "        self.tema=''\n",
    "        self.usuario_sanidad=Usuario('','sanidad',5,self.sanidad)\n",
    "        self.usuario_tecnologia=Usuario('','tecnologia',5,self.tecnologia)\n",
    "        self.usuario_ciencia=Usuario('','ciencia',5,self.ciencia)\n",
    "        self.page=''\n",
    "        #self.data = Data(self.webPage)\n",
    "    def create_widgets(self):\n",
    "        \"\"\"this creates all the objects in the window\"\"\"\n",
    "\n",
    "        self.title_lbl = ttk.Label(self,text = \"Seleccionar Noticia de Referencia\").grid(column = 0, row = 0)\n",
    "        self.label = ttk.Label(self, text = \"Medio\").grid(column = 0,\n",
    "                                                      row = 1)\n",
    "        self.label1 = ttk.Label(self, text = \"Categoria\").grid(column = 1,\n",
    "                                                      row =1)\n",
    "        \n",
    "        self.label2 = ttk.Label(self, text = \"Noticias\").grid(column = 2,row = 1)\n",
    "        self.combovar = StringVar()\n",
    "        self.combovar1 = StringVar()\n",
    "        self.combovar2 = StringVar()\n",
    "        self.top_text = StringVar()\n",
    "        self.articulos_similitud = StringVar()\n",
    "        self.medio = ttk.Combobox(self,textvariable = self.combovar,state = 'readonly')\n",
    "        self.medio['values'] = ('Medio 1','Mi País','Medio 2')\n",
    "        self.medio.current(0)\n",
    "        self.medio.grid(column = 0, row = 2)\n",
    "        self.categoria = ttk.Combobox(self,textvariable = self.combovar1,state = 'readonly')\n",
    "        self.categoria['values'] = ('Sanidad','Tecnología','Ciencia')\n",
    "        #self.categoria.current(0)\n",
    "        self.categoria.grid(column = 1, row = 2)\n",
    "        self.noticias = ttk.Combobox(self,textvariable = self.combovar2,state = 'readonly')\n",
    "        self.noticias.grid(column = 2, row = 2)\n",
    "        self.categoria.bind(\"<<ComboboxSelected>>\", self.selection_changed)\n",
    "        self.entry_var = tk.StringVar()\n",
    "        self.noticias.bind(\"<<ComboboxSelected>>\", self.getArticulo)\n",
    "        self.text_area = scrolledtext.ScrolledText(self, wrap=tk.WORD, height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.text_area.grid(column=0,columnspan=8, row=3,rowspan=2, pady=10, padx=10)\n",
    "        self.label4 = ttk.Label(self, text = \"Top:\").grid(column = 0,\n",
    "                                                      row = 7)\n",
    "        self.top_items = ttk.Combobox(self,textvariable =  self.top_text,state = 'readonly')\n",
    "        self.top_items['values'] = (1,2,3,4,5)\n",
    "        self.top_items.current(4)\n",
    "        self.top_items.grid(column = 0, row = 8)\n",
    "        self.top_articulos = ttk.Combobox(self,state = 'readonly')\n",
    "        self.label4 = ttk.Label(self, text = \"Ranking:\").grid(column = 2,\n",
    "                                                      row = 7)\n",
    "        self.top_articulos.grid(column = 2, row = 8)\n",
    "        self.top=ttk.Button(self, text=\"Buscar\",command=self.getTop)\n",
    "        self.top.grid(row=8,column=1)\n",
    "        self.top_articulos.bind(\"<<ComboboxSelected>>\", self.getOtrosAtriculos)\n",
    "        self.otras_noticias = scrolledtext.ScrolledText(self, wrap=tk.WORD,height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.otras_noticias.grid(column=0,columnspan=8, row=10,rowspan=2, pady=10, padx=10)\n",
    "   \n",
    "    def selection_changed(self, event):\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            init_list=self.sanidad.getTitulo()\n",
    "            #print(self.sanidad.getTitulo())\n",
    "        elif self.categoria.get() == 'Tecnología':\n",
    "            init_list=self.tecnologia.getTitulo()\n",
    "            #print(self.ciencia.getTitulo())\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            init_list=self.ciencia.getTitulo()\n",
    "            #print(self.ciencia.getTitulo())\n",
    "        lista = [x for x in init_list]\n",
    "        self.noticias['values'] = lista\n",
    "        self.noticias.current(0)\n",
    "\n",
    "        \n",
    "    def getArticulo(self,event):\n",
    "        self.text_area.delete(1.0, END)\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            self.usuario_sanidad=Usuario(self.noticias.get(),'sanidad',5,self.sanidad)\n",
    "            self.usuario_sanidad.cargarSeleccion()\n",
    "            self.text_area.insert(END,str(self.sanidad.mostrarArticulo()))\n",
    "        elif self.categoria.get() == 'Tecnología':\n",
    "            self.usuario_tecnologia=Usuario(self.noticias.get(),'tecnologia',5,self.tecnologia)\n",
    "            self.usuario_tecnologia.cargarSeleccion()\n",
    "            self.text_area.insert(END,self.tecnologia.mostrarArticulo())\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            self.usuario_ciencia=Usuario(self.noticias.get(),'ciencia',5,self.ciencia)\n",
    "            self.usuario_ciencia.cargarSeleccion()\n",
    "            self.text_area.insert(END,self.ciencia.mostrarArticulo())\n",
    "    def getTop(self):\n",
    "        self.top_articulos.set('')\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            self.usuario_sanidad.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.sanidad.similitud(self.sanidad.other_etiquetas)\n",
    "            init_list=self.sanidad.similitudes\n",
    "        elif self.categoria.get() == 'Tecnología':\n",
    "            self.usuario_tecnologia.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.tecnologia.similitud(self.tecnologia.other_etiquetas)\n",
    "            init_list=self.tecnologia.similitudes\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            self.usuario_ciencia.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.ciencia.similitud(self.ciencia.other_etiquetas)\n",
    "            init_list=self.ciencia.similitudes\n",
    "        \n",
    "        lista = [x for x in init_list]\n",
    "        self.top_articulos['values'] =lista\n",
    "        self.top_articulos.current(0)\n",
    "    def getOtrosAtriculos(self,event):\n",
    "        self.otras_noticias.delete(1.0, END)\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            articulo= self.sanidad.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        elif self.categoria.get() == 'Tecnología':\n",
    "            articulo= self.tecnologia.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            articulo= self.ciencia.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        \n",
    "    \n",
    "         \n",
    "#sanidad\n",
    "sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "#tecnologia\n",
    "tecnologia=WebPages('tecnologia','https://elpais.com/tecnologia/')\n",
    "tecnologia.escritura(tecnologia.miPais_news_scraper(),'tecnologia.data.json')\n",
    "#ciencia\n",
    "ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "data_sanidad=Data(sanidad)\n",
    "data_ciencia=Data(ciencia)\n",
    "data_tecnologia=Data(tecnologia)\n",
    "data_sanidad.saveArticle()       \n",
    "data_sanidad.getEtiqueta()\n",
    "data_ciencia.saveArticle()       \n",
    "data_ciencia.getEtiqueta()\n",
    "data_tecnologia.saveArticle()       \n",
    "data_tecnologia.getEtiqueta()\n",
    "main_window = tk.Tk()\n",
    "recomendacion_n = R_Noticias(main_window,data_sanidad,data_tecnologia,data_ciencia)\n",
    "main_window.geometry(\"750x550\")\n",
    "main_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "class B_Noticias(ttk.Frame):\n",
    "    \n",
    "    def __init__(self, main_window):\n",
    "        super().__init__(main_window)\n",
    "        self.grid()\n",
    "        self.create_widgets()\n",
    "    def create_widgets(self):\n",
    "        \"\"\"this creates all the objects in the window\"\"\"\n",
    "\n",
    "        self.title_lbl = ttk.Label(self,text = \"Busqueda de Noticia\").grid(column = 0, row = 0)\n",
    "        self.label = ttk.Label(self, text = \"Consulta:\").grid(column = 0,\n",
    "                                                      row = 1,padx=10, pady=10)\n",
    "        self.entry = ttk.Entry(self,width=30)\n",
    "        self.entry.grid(column=1,row=1,padx=10, pady=10)\n",
    "        self.label1 = ttk.Label(self, text = \"Top:\").grid(column = 0,\n",
    "                                                      row = 3, pady=10, padx=10)\n",
    "        self.combovar = StringVar()\n",
    "        self.top_items = ttk.Combobox(self,textvariable = self.combovar,state = 'readonly')\n",
    "        self.top_items['values'] = (1,2,3,4,5)\n",
    "        self.top_items.current(4)\n",
    "        self.top_items.grid(column = 1, row = 3)\n",
    "        self.label2 = ttk.Label(self, text = \"Filtrar:\").grid(column = 2,\n",
    "                                                      row = 3)\n",
    "        self.combovar_medio = StringVar()\n",
    "        self.medio = ttk.Combobox(self,textvariable = self.combovar_medio,state = 'readonly')\n",
    "        self.medio['values'] = ('Todos','Medio 1','Mi pais','Medio 3')\n",
    "        self.medio.current(0)\n",
    "        self.medio.grid(column = 3, row = 3)\n",
    "        self.buscar=ttk.Button(self, text=\"Buscar\")\n",
    "        self.buscar.grid(row=3,column=4)\n",
    "        self.label3 = ttk.Label(self, text = \"Ranking:\").grid(column = 0,\n",
    "                                                      row = 4)\n",
    "        self.combovar_ranking = StringVar()\n",
    "        self.ranking = ttk.Combobox(self,textvariable = self.combovar_ranking,state = 'readonly')\n",
    "        self.ranking.grid(column = 0, row = 5)\n",
    "        self.label3 = ttk.Label(self, text = \"Texto de la noticia:\").grid(column = 1,\n",
    "                                                      row = 4)\n",
    "        self.noticia = scrolledtext.ScrolledText(self, wrap=tk.WORD,height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.noticia.grid(column=1,columnspan=8, row=5,rowspan=2, pady=10, padx=10)\n",
    "\n",
    "        \n",
    "\n",
    "main_window = tk.Tk()\n",
    "recomendacion_n = B_Noticias(main_window)\n",
    "main_window.geometry(\"1000x700\")\n",
    "main_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2621844",
   "metadata": {},
   "source": [
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter.messagebox import showinfo\n",
    "sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "data_sanidad=Data(sanidad)\n",
    "tecnologia=WebPages('tecnologia','https://elpais.com/tecnologia/')\n",
    "tecnologia.escritura(tecnologia.miPais_news_scraper(),'tecnologia.data.json')\n",
    "data_tecnologia=Data(tecnologia)\n",
    "ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "data_ciencia=Data(ciencia)\n",
    "# root window\n",
    "root = tk.Tk()\n",
    "root.geometry('300x120')\n",
    "root.title('Progressbar Demo')\n",
    "\n",
    "\n",
    "def update_progress_label(file):\n",
    "    return f\"Current Progress: {pb['value']}%\",\" files downloaded\",file\n",
    "\n",
    "\n",
    "def progress():\n",
    "    if pb['value'] < 100:\n",
    "        pb['value'] += 20\n",
    "        value_label['text'] = update_progress_label('')\n",
    "    else:\n",
    "        showinfo(message='The progress completed!')\n",
    "\n",
    "\n",
    "def stop():\n",
    "    pb.stop()\n",
    "    value_label['text'] = update_progress_label('stop')\n",
    "\n",
    "def cargando_sanidad():\n",
    "    data_sanidad.saveArticle()       \n",
    "    data_sanidad.getEtiqueta()\n",
    "    pb['value'] += 33.4\n",
    "    value_label['text'] = update_progress_label('/Sanidad')\n",
    "def cargando_ciencia():\n",
    "    data_ciencia.saveArticle()       \n",
    "    data_ciencia.getEtiqueta()\n",
    "    value_label['text'] = update_progress_label('/Ciencia')\n",
    "    pb['value'] += 33.33\n",
    "def cargando_tecnologia():\n",
    "    data_tecnologia.saveArticle()       \n",
    "    data_tecnologia.getEtiqueta()\n",
    "    value_label['text'] = update_progress_label('/Tecnologia')\n",
    "    pb['value'] += 33.33\n",
    "    if pb['value'] == 100:\n",
    "        showinfo(message='The progress completed!')\n",
    "    \n",
    "# progressbar\n",
    "pb = ttk.Progressbar(\n",
    "    root,\n",
    "    orient='horizontal',\n",
    "    mode='determinate',\n",
    "    length=280\n",
    ")\n",
    "# place the progressbar\n",
    "pb.grid(column=0, row=0, columnspan=2, padx=10, pady=20)\n",
    "\n",
    "# label\n",
    "value_label = ttk.Label(root, text=update_progress_label(''))\n",
    "value_label.grid(column=0, row=1, columnspan=2)\n",
    "\n",
    "# start button\n",
    "ciencia = ttk.Button(root,text='Download Ciencia',command=cargando_ciencia)\n",
    "ciencia.grid(column=0, row=2, padx=10, pady=10, sticky=tk.E)\n",
    "\n",
    "sanidad = ttk.Button(root,text='Download Sanidad',command=cargando_sanidad)\n",
    "sanidad.grid(column=1, row=2, padx=10, pady=10, sticky=tk.W)\n",
    "tecnologia = ttk.Button(root,text='Download Tecnologia',command=cargando_tecnologia)\n",
    "tecnologia.grid(column=2, row=2, padx=10, pady=10, sticky=tk.W)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc38a5",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "documentos = [\"The best Italian restaurant enjoy the best pasta.\",\"The best the best American restaurant.\", \"American restaurant enjoy the best hamburger.\",\n",
    "              \"Korean restaurant enjoy the best bibimbap\"] #Documents\n",
    "query = [\"The best the best American restaurant.\"] #Query\n",
    "#stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "stopWords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "#print transformer\n",
    "\n",
    "vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "vector_query = vectorizer.transform(query).toarray()\n",
    "\n",
    "print ('Vector de documentos', vectorizer.vocabulary_)\n",
    "print('Vector de documentos en array:',vector_documentos)\n",
    "print ('Vector de query en array', vector_query)\n",
    "print('--------------------------------------------')\n",
    "#funcion del coseno se le introducen dos valores \n",
    "cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "i=0\n",
    "x=0\n",
    "for vector in vector_documentos:\n",
    "    print (vector)\n",
    "    for testV in vector_query:\n",
    "        if np.array_equal(vector,testV):\n",
    "            print(vector,'y',testV)\n",
    "            x=i\n",
    "        print (testV)\n",
    "        cosine = cx(vector, testV)\n",
    "        print (cosine)\n",
    "    i=i+1\n",
    "print('X ESTA EN LA POSICION',x)\n",
    "for testV in vector_query:\n",
    "    print ('a',testV)\n",
    "    cosine = similarity_scores = vector_documentos.dot(testV)/(np.linalg.norm(vector_documentos, axis=1) * np.linalg.norm(testV))\n",
    "print ('similitud en el documento N: ',cosine)\n",
    "\n",
    "print('--------------------------------------------')\n",
    "stop = list(stopwords.words('english'))\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',tokenizer=stemming_tokenizer,use_idf=True,norm='l2')\n",
    "tfidf_vectorizer2 = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "#print ('QUERY',tfidf_query.toarray())\n",
    "print (tfidf_matrix.toarray())\n",
    "\n",
    "#print ('similitud en el documento N: ',cosine)\n",
    "#importante \n",
    "cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "print (cosine)\n",
    "\n",
    "\"\"\"\n",
    "transformer.fit(vector_documentos)\n",
    "print()\n",
    "print (transformer.transform(vector_documentos).toarray())\n",
    "\n",
    "transformer.fit(vector_query)\n",
    "print ()\n",
    "tfidf = transformer.transform(vector_query)\n",
    "print (tfidf.todense())\n",
    "for v in transformer.transform(vector_documentos).toarray():\n",
    "    for q in transformer.transform(vector_query).toarray():\n",
    "        cosine = cx(v, q)\n",
    "        print ('similitud en el documento N: ',cosine)\"\"\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
