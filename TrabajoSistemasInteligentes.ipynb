{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc595c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d6d370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Arrow in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Arrow) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adobr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.0->Arrow) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#esta es una libreria que me permite manejar fechas, tuve problemas con datetime ya que datetime no reconoce fechas\n",
    "#acortadas en espaÃ±ol, mas no palabras como Diciembre, esas si las reconoce.\n",
    "!pip install Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e81595af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement request-html (from versions: none)\n",
      "ERROR: No matching distribution found for request-html\n"
     ]
    }
   ],
   "source": [
    "!pip install request-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a451098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user --install-option=\"--prefix=\" -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682acabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d258b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afea645",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa72f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web scrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#maneja mi archivo json\n",
    "import json\n",
    "#lo uso para remover archivos y no duplicar\n",
    "import os\n",
    "from datetime import datetime\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "import arrow\n",
    "import sys\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "784f4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQuery:\n",
    "    \n",
    "    def __init__(self,sanidad,ciencia):\n",
    "        self.sanidad=sanidad\n",
    "        self.ciencia=ciencia\n",
    "    def getSanidad(self):\n",
    "        return self.sanidad\n",
    "    def getCiencia(self):\n",
    "        return self.ciencia\n",
    "    def lecturaJsonV(self,tema):  \n",
    "        tema_=tema+'.data.json'\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[tema]\n",
    "      #TF-IDF\n",
    "    def lecturaSanidad(self):\n",
    "        tema_=self.sanidad+'.data.json'\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[self.sanidad]\n",
    "    def lecturaCiencia(self):\n",
    "        tema_=self.ciencia,'.data.json'\n",
    "        print(tema_)\n",
    "        with open(tema_) as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[self.ciencia]\n",
    "    def getNameArticulos(self,json):\n",
    "        articulos=[]\n",
    "        for item in json:\n",
    "            #titulos= item['titulo'] == self.titulo:\n",
    "            articulos.append(item['articulo'])\n",
    "        print(articulos)\n",
    "        return articulos\n",
    "    #con esto unire los nombres de los articulos\n",
    "    #y unire la query a los articulos\n",
    "    def unirArrays(self,a,b):\n",
    "        c=np.append(a,b)\n",
    "        return c\n",
    "    #devuelve un array de articulos\n",
    "    def getAllArticulos(self,json):\n",
    "        arr_articulos=[]\n",
    "        for item in json:\n",
    "            f = open(item, \"r\", encoding=\"utf8\")\n",
    "            leer=str(f.read())\n",
    "            arr_articulos.append(leer.strip('\"\"'))\n",
    "            f.close()\n",
    "        return arr_articulos\n",
    "    #se le pone una lista de documentos mas la query y la query\n",
    "    #devuelve un vector de documentos con la query insertada en tf\n",
    "    #lo utilizo para poder calcular la posicion de la query y ver las frecuencias\n",
    "    #Ejemplo: [[0 1 0 2 3],[0 0 0 1 2]]->frecuencias\n",
    "    def calcularTF(self,documentos,query):\n",
    "        #stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "        stopWords = stopwords.words('spanish')\n",
    "        vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "        vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "        vector_query = vectorizer.transform(query).toarray()\n",
    "        #funcion del coseno se le introducen dos valores \n",
    "        \n",
    "        cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "        i=0\n",
    "        x=0\n",
    "        posicionQuery=0\n",
    "        for vector in vector_documentos:\n",
    "            #print (vector)\n",
    "            for testV in vector_query:\n",
    "                if np.array_equal(vector,testV):\n",
    "                    #print(vector,'y',testV)\n",
    "                    posicionQuery=i\n",
    "                #print (testV)\n",
    "                cosine = cx(vector, testV)\n",
    "                #print (cosine)\n",
    "            i=i+1\n",
    "        return posicionQuery\n",
    "    #Funcion que convierte documentos en vectores y calcula la similitud\n",
    "    #esto facilitara obtener la similitud para poder discriminar mejor \n",
    "    #documentos\n",
    "    def vectorTF_IDF(self,documentos):\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english',tokenizer=stemming_tokenizer,use_idf=True,norm='l2')\n",
    "        #tfidf_vectorizer2 = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "        #tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "       # cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        #print (cosine)\n",
    "        return tfidf_matrix\n",
    "    def similitudTF_IDF(self,vector_documento,posicion_query):\n",
    "        cosine = cosine_similarity(vector_documento[posicion_query], vector_documento)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "436a51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    #la data la obtengo de las paginas, es dependiente\n",
    "    def __init__(self,webPage):\n",
    "        self.titulo = []\n",
    "        self.descripcion = ''\n",
    "        self.fecha=[]\n",
    "        self.enlace=[]\n",
    "        self.articulo=[]\n",
    "        self.webPage=webPage\n",
    "        self.etiqueta=[]\n",
    "        self.max=0\n",
    "        self.similitudes=[]\n",
    "        self.other_etiquetas=[]\n",
    "        self.posicionQuery=0\n",
    "    #def __init__(self):\n",
    "        #self.webPage=webPage\n",
    "    #metodo para leer jsons\n",
    "    def lecturaJson(self):\n",
    "        with open(self.webPage.getTema()+'.data.json') as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data\n",
    "     #metodo para leer jsons\n",
    "        \n",
    "    def lecturaJsonV(tema,self):\n",
    "        with open(tema+'.data.json') as file:\n",
    "            data = json.load(file)\n",
    "            file.close()\n",
    "        return data[tema]\n",
    "    #metodo para aÃ±adir keys a jsons\n",
    "    #|key=llave del json\n",
    "    #|name=valor de la key\n",
    "    #|posicion=posicion a guardar dentro del json\n",
    "    def add(self,key,name,posicion):\n",
    "        data=self.lecturaJson()\n",
    "        data[self.webPage.getTema()][posicion][key] = name\n",
    "        with open(self.webPage.getTema()+'.data.json', 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "            json_file.close()\n",
    "    #aÃ±ado la ubicacion del articulo en el json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addTxt(self,name,posicion):\n",
    "        self.add('articulo',name,posicion)\n",
    "    #aÃ±ado las etiquetas al json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addEtiqueta(self,etiqueta,posicion):\n",
    "        self.add('etiquetas',etiqueta,posicion)\n",
    "    #aÃ±ado la fecha al json\n",
    "    #|name=nombre del valor de la key\n",
    "    #|posicion=posicion a guardar\n",
    "    def addFecha(self,fecha,posicion):\n",
    "        self.add('fecha',fecha,posicion)\n",
    "    #aqui limpio la fecha del articulo para que se vea 05-12-2021 asi\n",
    "    #|date=fecha string\n",
    "    def setDate(self,date):\n",
    "        date1=date.strip('UTC')\n",
    "        fdate = date1.split('-', 1)[0]\n",
    "        fecha = arrow.get(fdate, 'DD MMM YYYY',locale='ES')\n",
    "        d=str(fecha)\n",
    "        fecha_ = d.split('T', 1)[0]\n",
    "        return fecha_\n",
    "    #metodo para extraer valores del json con sus keys\n",
    "    #|value=array para aÃ±adir los items a un array\n",
    "    #|nombre=la key del json\n",
    "    def get(self,value,nombre):\n",
    "        #aqui saco todos los titulos\n",
    "        data=self.lecturaJson()\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            value.append(item[nombre])\n",
    "        return value\n",
    "    #metodo para obtener TODOS los titulos dentro del json\n",
    "    def getTitulo(self):\n",
    "        arr=[]\n",
    "        return self.get(arr,'titulo')\n",
    "    #metodo para obtener TODAS fecha en el segundo link y guardarlo en el json\n",
    "    def getFecha(self):\n",
    "        i=0\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('div', class_='a_md_f')\n",
    "            if elements:\n",
    "                for item in elements:\n",
    "                    if item.select('time'):\n",
    "                        self.fecha.append(self.setDate(self.webPage.parseo(item.select('time'))))\n",
    "                        self.addFecha(self.fecha[i],i)\n",
    "                    else:\n",
    "                        print('no tiene time')\n",
    "            else: \n",
    "                #despues de tanta vaina voy a eliminar los que no siguen el patron que yo tengo\n",
    "               #caso excepcional para TECNOLOGIA ya que contiene articulos que son ads pero tambien forman parte de los articulos\n",
    "                #elements=noticia.find_all('div', class_='a_pt | uppercase color_gray_medium_lighter')\n",
    "                #for item in elements:\n",
    "                self.fecha.append(datetime.today().strftime('%Y-%m-%d'))\n",
    "                self.addFecha(self.fecha[i],i)\n",
    "            i=i+1\n",
    "        return self.fecha\n",
    "    #metodo para obtener el enlace dentro del json\n",
    "    def getEnlace(self):\n",
    "        #aqui saco todos los titulos\n",
    "        self.enlace=[]\n",
    "        return self.get(self.enlace,'enlace')\n",
    "    #metodo para obtener el articulo dentro del json\n",
    "    def getArticulo(self):\n",
    "        i=0\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('div', class_='a_c clearfix')\n",
    "            if elements:    \n",
    "                for item in elements:\n",
    "                    self.articulo.append(str(self.webPage.parseo(item.select('p'))))\n",
    "            else:\n",
    "                print('no encontrado, FALTA ARTICULO')\n",
    "             #caso excepcional para TECNOLOGIA ya que contiene articulos que son ads pero tambien forman parte de los articulos\n",
    "                #elements=noticia.find_all('div',class_='a_b article_body | color_gray_dark initial_letter especial a_b__e col desktop_8 tablet_8 mobile_4 margin_center')\n",
    "                #for item in elements:\n",
    "                self.articulo.append('Debido a que no es compatible con el Scrapper no se puede mostrar este articulo')\n",
    "            i=i+1\n",
    "        return self.articulo\n",
    "    #metodo obtengo la etiqueda de TODAS las paginas.\n",
    "    def getEtiqueta(self):\n",
    "        i=0\n",
    "        arr_etiquetas=[]\n",
    "        self.etiqueta=[]\n",
    "        self.enlace=self.getEnlace()\n",
    "        for link in self.enlace:\n",
    "            noticia=self.webPage.getRequest(link)\n",
    "            elements=noticia.find_all('ul', class_='_df _ls')\n",
    "            for item in elements:\n",
    "                e=self.webPage.parseo(item.select('li'))\n",
    "                arr_etiquetas=e.split(',')\n",
    "                self.etiqueta.append(arr_etiquetas)\n",
    "            self.addEtiqueta(arr_etiquetas,i)\n",
    "            i=i+1\n",
    "            self.other_etiquetas=self.etiqueta\n",
    "        return self.etiqueta\n",
    "    #metodo para guardar el articulo en un TXT\n",
    "    def saveArticle(self):\n",
    "        i=0\n",
    "        #emparejamos titulo y articulo\n",
    "        self.titulo=self.getTitulo()\n",
    "        self.articulo=self.getArticulo()\n",
    "        self.fecha=self.getFecha() \n",
    "        print('TITULO')\n",
    "        print(len(self.titulo))\n",
    "        print('ARTICULO')\n",
    "        print(len(self.articulo))\n",
    "        print('FECHAS')\n",
    "        print(len(self.fecha))\n",
    "        for articulo, titulo,fecha in zip(self.articulo, self.titulo,self.fecha): #obtenemos los valores en cada iteraciÃ³n\n",
    "            parrafo=titulo+'\\n'+articulo\n",
    "            parrafo_=parrafo.strip(\"[]\")\n",
    "            tema=self.webPage.getTema()\n",
    "            nombre=tema+'.'+fecha+'.'+str(i)+'.txt'\n",
    "            self.addTxt(nombre,i)\n",
    "            self.webPage.escrituraTexto(parrafo_,nombre)\n",
    "            i=i+1   \n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|titulo=titulo del articulo\n",
    "    def setTitulo(self,titulo):\n",
    "        self.titulo=titulo\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|descripcion=descripcion del articulo\n",
    "    def setDescripcion(self,descripcion):\n",
    "        self.descripcion=descripcion\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|fecha=fecha del articulo\n",
    "    def setFecha(self,fecha):\n",
    "        self.fecha=fecha\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|enlace=enlace del articulo\n",
    "    def setEnlace(self,enlace):\n",
    "        self.enlace=enlace\n",
    "    #obtenemos la descripcion (borrar no se usa)\n",
    "    def getDescripcion(self):\n",
    "        print(self.descripcion)\n",
    "    #cuando el usuario defina el articulo a ver el dato se basara en el articulo seleccionado\n",
    "    #|etiqueta=etiqueta del articulo\n",
    "    def setEtiqueta(self,etiqueta):\n",
    "        self.etiqueta=etiqueta\n",
    "    #setea el valor del top\n",
    "    #|maxi=top de articulos\n",
    "    def setMax(self,maxi):\n",
    "        self.max=maxi\n",
    "    #aqui leemos exclusivamente un txt\n",
    "    #|nombre=nombre del articulo\n",
    "    def lecturaTxt(self,nombre):\n",
    "        f = open(nombre, \"r\", encoding=\"utf8\")\n",
    "        texto=f.read()\n",
    "        f.close()\n",
    "        return texto\n",
    "    #este metodo es para obtener un elemento por su key \n",
    "    #|key=llave del json\n",
    "    def getX(self,key):\n",
    "        #leo el json\n",
    "        value=[]\n",
    "        data=self.lecturaJson()\n",
    "        #recorro el json y busco su txt\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            #verificamos si la posicion esta en el top\n",
    "            value.append(item[key])\n",
    "            #self.similitudes=value\n",
    "            # me devuelve un array de txt\n",
    "        return value\n",
    "    #metodo para mostrar las noticias en el top\n",
    "    #|posicion_noticia= es la posicion de la noticia a obtener\n",
    "    def getSimilitud_Paginas(self,posicion_noticia):\n",
    "        pag_similitud=[]\n",
    "        articulo=''\n",
    "        #cargamos el array de textos [texto1.txt,texto2.txt,texto3.txt] hasta la posicion top\n",
    "        articulos=self.getX('articulo')\n",
    "        #cuando se seleccione el boton me dira que noticia es: la 1, la 2,etc \n",
    "        #leo el texto en la posicion estipulada\n",
    "        #verifico que el valor sea menor que el maximo\n",
    "        articulo=self.lecturaTxt(articulos[posicion_noticia])\n",
    "        #hacemos match con las similitudes\n",
    "        return articulo\n",
    "    #TF-IDF\n",
    "    def getNameArticulos(json,self):\n",
    "        articulos=[]\n",
    "        for item in json:\n",
    "            #titulos= item['titulo'] == self.titulo:\n",
    "            articulos.append(item['articulo'])\n",
    "        return articulos\n",
    "    #con esto unire los nombres de los articulos\n",
    "    #y unire la query a los articulos\n",
    "    def unirArrays(a,b,self):\n",
    "        c=np.append(a,b)\n",
    "        return c\n",
    "    #devuelve un array de articulos\n",
    "    def getAllArticulos(json,self):\n",
    "        arr_articulos=[]\n",
    "        for item in json:\n",
    "            f = open(item, \"r\", encoding=\"utf8\")\n",
    "            leer=str(f.read())\n",
    "            arr_articulos.append(leer.strip('\"\"'))\n",
    "            f.close()\n",
    "        return arr_articulos\n",
    "    #se le pone una lista de documentos mas la query y la query\n",
    "    #devuelve un vector de documentos con la query insertada en tf\n",
    "    #lo utilizo para poder calcular la posicion de la query y ver las frecuencias\n",
    "    #Ejemplo: [[0 1 0 2 3],[0 0 0 1 2]]->frecuencias\n",
    "    def calcularTF(documentos,query,self):\n",
    "        #stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "        stopWords = stopwords.words('spanish')\n",
    "        vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "        vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "        vector_query = vectorizer.transform(query).toarray()\n",
    "        #funcion del coseno se le introducen dos valores \n",
    "        \n",
    "        cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "        i=0\n",
    "        x=0\n",
    "        posicionQuery=0\n",
    "        for vector in vector_documentos:\n",
    "            print (vector)\n",
    "            for testV in vector_query:\n",
    "                if np.array_equal(vector,testV):\n",
    "                    print(vector,'y',testV)\n",
    "                    posicionQuery=i\n",
    "                print (testV)\n",
    "                cosine = cx(vector, testV)\n",
    "                print (cosine)\n",
    "            i=i+1\n",
    "        return posicionQuery\n",
    "    #Funcion que convierte documentos en vectores y calcula la similitud\n",
    "    #esto facilitara obtener la similitud para poder discriminar mejor \n",
    "    #documentos\n",
    "    def vectorTF_IDF(documentos,self):\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        #tfidf_vectorizer2 = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "        #tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "       # cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        #print (cosine)\n",
    "        return tfidf_matrix\n",
    "    def similitudTF_IDF(vector_documento,posicion_query,self):\n",
    "        cosine = cosine_similarity(vector_documento[posicion_query], vector_documento)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "        return cosine\n",
    "    def mostrarArticulo(self):\n",
    "        texto=''\n",
    "        \n",
    "        #consultamos en el json el nombre del txt\n",
    "        data=self.lecturaJson()\n",
    "        for item in data[self.webPage.getTema()]:\n",
    "            if item['titulo'] == self.titulo:\n",
    "                texto=item['articulo']\n",
    "        #abrimos el txt y lo leemos\n",
    "        f = open(texto, \"r\", encoding=\"utf8\")\n",
    "        self.articulo=str(f.read())\n",
    "        a=self.articulo.strip('\"\"')\n",
    "        self.articulo=a\n",
    "        f.close()\n",
    "        return self.articulo\n",
    "    #estos son los calculos de la similitud\n",
    "    #|match=match del array1 con array2\n",
    "    #ejemplo: [a,b,c]U[d,c,r]=c 1 match\n",
    "    #|e1=es el array que escogio el usuario\n",
    "    #|array2= son los otros arrays top\n",
    "    def calculos(self,e1,array2,match):\n",
    "       # print('match encontrados',match)\n",
    "        #print('formula',str(2),'*',str(match),'/',str((len(e1))),'+',str(len(array2)))\n",
    "        formula=(2*match)/((len(e1))+(len(array2)))\n",
    "        return formula\n",
    "    #metodo para rankear la lista, devuelve una lista de las nuevas posiciones de los elementos\n",
    "    #|li=es el array de similitudes\n",
    "    def integers(self,li):\n",
    "        arr=[]\n",
    "        for i in range(len(li)):\n",
    "            arr.append(i)\n",
    "        return arr\n",
    "    def sorting(self,li):\n",
    "        arr=self.integers(li)\n",
    "        for i in range(len(li)):\n",
    "            for j in range(len(li)):\n",
    "                if li[i] > li[j]:\n",
    "                    li[j],li[i] = li[i],li[j]\n",
    "                    arr[j],arr[i] = arr[i],arr[j]\n",
    "        self.similitudes=self.solo_Top(li)\n",
    "        arr_=[]\n",
    "        arr_=self.solo_Top(arr)\n",
    "        return arr_\n",
    "    #esto lo hago solo por si acaso en las similitudes tengo algo ejemplo:\n",
    "    #[covid-19 enfermedad, covid]U[covid-19, covid] para que no diga que son totalmente iguales o algo asi.\n",
    "    def eliminarEspacios(self,arr):\n",
    "        new_arr=[]\n",
    "        for item in arr:\n",
    "            a_string=str(item)\n",
    "            a=a_string.replace(\" \", \"\")\n",
    "            new_arr.append(a)\n",
    "        return new_arr\n",
    "     #aqui rompo el array y saco solo el top\n",
    "    #|arr=array recortado\n",
    "    def solo_Top(self,arr):\n",
    "        new_arr=[]\n",
    "        i=0\n",
    "        maxi=self.max\n",
    "        for item in arr:\n",
    "            if i<maxi:\n",
    "                new_arr.append(item)\n",
    "            else:\n",
    "                break\n",
    "            i=i+1\n",
    "        return new_arr\n",
    "    #aqui obtengo las similitudes entr etiquetas\n",
    "    #|e1= es el array que escogio el usuario\n",
    "    def similitud(self,e2):\n",
    "        n_noticia=0\n",
    "        #contador de similitudes\n",
    "        contador_match=0\n",
    "        maximo=self.max\n",
    "        i=0\n",
    "        e1=self.etiqueta\n",
    "        e1_=self.eliminarEspacios(e1)\n",
    "        #print(self.etiqueta)\n",
    "        resultados=[]\n",
    "        #aqui sera en el array simple ['comida','perro','gato']\n",
    "        for array2 in e2:\n",
    "            contador_match=0\n",
    "        #solo obtendre las similitudes de los top\n",
    "            array2_=self.eliminarEspacios(array2)\n",
    "            #[['comida','perro','avispa'],['azul','perro','can']]  \n",
    "            for item in array2_:\n",
    "                #print('entrando en el bucle')\n",
    "                ##print(item)\n",
    "                for array1 in e1_:\n",
    "                    #print('_______________________________________')\n",
    "                    #print(item,'es igual a',array1)\n",
    "                    if str(array1) == str(item):\n",
    "                        contador_match=contador_match+1\n",
    "                        #print(item,'SI igual a',array1)\n",
    "                        #print()\n",
    "                        #print('array encontrado similitud:',array2_)          \n",
    "                    resultado=self.calculos(e1_,array2_,contador_match)\n",
    "                    #print('la similitud total es de:',resultado)\n",
    "                    resultado_=resultado*100\n",
    "                #aÃ±adimos el resultado en un array de similitudes\n",
    "            i=i+1\n",
    "            \n",
    "            resultados.append(resultado_)\n",
    "            #print(array2)\n",
    "            #print('grado de similitud con array1',str(resultado_)+'%')\n",
    "            #print('_______________________________________')\n",
    "        arr_final=[]\n",
    "        arr_final=self.sorting(resultados)\n",
    "        return arr_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8e0348d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Usuario():\n",
    "    def __init__(self, titulo, categoria,top,data):\n",
    "        self.titulo = titulo\n",
    "        self.categoria = categoria\n",
    "        self.data = data\n",
    "        self.top=top\n",
    "    #seteamos los campos de datos para que nos muestre los necesarios nada mas\n",
    "    def cargarSeleccion(self):\n",
    "        data=self.data.lecturaJson()\n",
    "        #print('categoria es',self.categoria)\n",
    "        for item in data[self.categoria]:\n",
    "            #validamos que la seccion seleccionada este en el json\n",
    "            if self.titulo  in item['titulo']:\n",
    "                self.data.setEnlace(item[\"enlace\"]) \n",
    "                self.data.setTitulo(item[\"titulo\"])\n",
    "                self.data.setDescripcion(item[\"descripcion\"]) \n",
    "                self.data.setFecha(item[\"fecha\"])\n",
    "                self.data.setEtiqueta(item[\"etiquetas\"])\n",
    "                self.data.setMax(self.top)\n",
    "    def setTop(self,top):\n",
    "        self.top=top\n",
    "        self.data.setMax(self.top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6157ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WebPages():\n",
    "    def __init__(self, tema, url):\n",
    "        self.tema = tema\n",
    "        self.url = url\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "   \n",
    "    def getRequest(self,url):\n",
    "        request = requests.get(url, headers=self.headers)\n",
    "        html = request.content.decode(\"utf-8\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    #metodo que escribe un archivo\n",
    "    #|texto=lo que quieras introducir en el archivo\n",
    "    #|nombre=nombre del archivo \n",
    "    def escritura(self,texto,nombre):\n",
    "        #si existe un path con este nombre lo quitaremos, evita duplicados\n",
    "        if os.path.exists(nombre):\n",
    "            os.remove(nombre)\n",
    "            #print('este path existe, lo eliminaremos')\n",
    "        with open(nombre, 'w') as f:\n",
    "            json.dump(texto, f)\n",
    "            f.close()\n",
    "    def escrituraTexto(self,texto,nombre):\n",
    "        #si existe un path con este nombre lo quitaremos, evita duplicados\n",
    "        if os.path.exists(nombre):\n",
    "            os.remove(nombre)\n",
    "            #print('este path existe, lo eliminaremos')\n",
    "        file= open(nombre, 'w', encoding='utf-8')\n",
    "        file.write(texto)\n",
    "        file.close()\n",
    "    #parseo: se encarga de pasar el fragmento html a texto\n",
    "    #|fragmento=pedazo de html ejemplo=<a>...</a> \n",
    "    def parseo(self,fragmento):\n",
    "    #vuelvo string el fragmento html\n",
    "        word=str(fragmento)\n",
    "    #remueve los brackets\n",
    "        parsedword=word.strip(\"[]\")\n",
    "    #obtengo el texto dentro del html, en caso de que halla texto contenido\n",
    "        soup1=BeautifulSoup(parsedword, from_encoding='utf-8').get_text()\n",
    "        return soup1\n",
    "    #inicia el scrappeo a los primeros links\n",
    "    def miPais_news_scraper(self):\n",
    "        article_list={}\n",
    "        article_list[self.tema]=[]\n",
    "        soup=self.getRequest(self.url)\n",
    "    \n",
    "    # Encontramos todos los articulos necesarios\n",
    "        elements=soup.find_all('article', class_='c')\n",
    "    #de todos los articulos iremos revisando item x item.\n",
    "        for item in elements:\n",
    "            #aqui es donde tomo los enlaces,titulos,entradillas, fechas y las introduzco en un json\n",
    "            enlace='https://elpais.com'+item.a['href']\n",
    "            article_list[self.tema].append({'titulo':self.parseo(item.select('header h2 a')),'enlace':enlace,'descripcion':self.parseo(item.select('p'),),\n",
    "                                            'fecha':\"\",'articulo':'','etiquetas':[]} )\n",
    "            \n",
    "        return article_list   \n",
    "        \n",
    "    #obtengo el tema;sanidad,tecnologia,ciencia.\n",
    "    def getTema(self):\n",
    "        return self.tema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by Adilem Dobras\n",
    "#sanidad\n",
    "if __name__ == '__main__':\n",
    "    sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "    sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "    #ciencia\n",
    "    ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "    ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "    data_sanidad=Data(sanidad)\n",
    "    data_sanidad.saveArticle() \n",
    "    #data_sanidad.string('Hola.:')\n",
    "    data_ciencia=Data(ciencia)\n",
    "    data_ciencia.saveArticle()    \n",
    "    #data_sanidad.getEtiqueta()\n",
    "           \n",
    "    #data_ciencia.getEtiqueta()\n",
    "    tf_idf=DataQuery('sanidad','ciencia')\n",
    "    #print(tf_idf.getCiencia())\n",
    "    #abro el json\n",
    "    json_sanidad=tf_idf.lecturaJsonV('sanidad')\n",
    "    #saco las direcciones de los articulos\n",
    "    #print(json_sanidad)\n",
    "    articulos_sanidad=tf_idf.getNameArticulos(json_sanidad)\n",
    "    #abro el json\n",
    "    json_ciencia=tf_idf.lecturaJsonV('ciencia')\n",
    "    #saco las direcciones de los articulos \n",
    "    articulos_ciencia=tf_idf.getNameArticulos(json_ciencia)\n",
    "    #inserto todas las direcciones en un array\n",
    "    articulos=tf_idf.unirArrays(articulos_sanidad,articulos_ciencia)\n",
    "    print(articulos)\n",
    "    #consigo el array de documentos\n",
    "    array_documentos=tf_idf.getAllArticulos(articulos)\n",
    "    #consulto la query al usuario y la inserto en el array de documentos\n",
    "    array_query=['Eso plantea problemas desde el punto de vista tecnolÃ³gico, porque cuando se utilizan como ingrediente en ciertos productos, como palmeras de chocolate, empanadas, cruasanes, etc., las caracterÃ­sticas organolÃ©pticas se ven perjudicadas: se derriten a temperatura ambiente, aportan un aspecto poco apetecible, tienen una textura menos agradable, etc., Para tratar de solucionar esos inconvenientes sin tener que abandonar el uso de aceites vegetales, se echÃ³ mano de un proceso que se conoce como hidrogenaciÃ³n, que, dicho mal y pronto, consiste en aÃ±adir Ã¡tomos de hidrÃ³geno a los Ã¡cidos grasos de los aceites para cambiar su estructura, de manera que pasan de ser insaturados (y lÃ­quidos a temperatura ambiente) a ser un poco mÃ¡s saturados (y un poco mÃ¡s sÃ³lidos). De este modo se consigue que los aceites sean algo mÃ¡s sÃ³lidos de lo habitual, asÃ­ que son mÃ¡s estables, se enrancian con menos facilidad y aportan a los productos unas mejores caracterÃ­sticas, sobre todo de aspecto y textura., AsÃ­ es como se obtienen las famosas grasas hidrogenadas. El problema es que ese proceso puede dar lugar a la formaciÃ³n de los dichosos Ã¡cidos grasos trans, que durante muchos aÃ±os ostentaron el tÃ­tulo de enemigo pÃºblico nÃºmero uno. HabÃ­a motivos justificados para ello, porque hoy sabemos a ciencia cierta que su consumo aumenta el riesgo de sufrir enfermedades cardiovasculares. Por esta razÃ³n las autoridades sanitarias coinciden en que es necesario reducir su consumo o eliminarlos totalmente de la dieta. Esto, sumado a la preocupaciÃ³n social, llevÃ³ a muchos fabricantes a buscar alternativas para evitar la presencia de estas grasas trans en los alimentos., Una de las soluciones consistiÃ³ en mejorar los procesos con los que se obtienen esas grasas vegetales mÃ¡s sÃ³lidas. Hoy en dÃ­a la presencia de grasas hidrogenadas en la lista de ingredientes de un producto ya no implica necesariamente que contenga grasas trans., Editorial: Ediciones Destino, ColecciÃ³n: Imago Mundi, NÃºmero de pÃ¡ginas: 376, Precio: 17,90â¬, De todos modos, como consumidores no tenemos forma de conocer la cantidad de grasas trans que contiene un producto, porque esa informaciÃ³n no se muestra en la etiqueta, a diferencia de lo que ocurre en paÃ­ses como Estados Unidos donde es obligatorio. De hecho, en el momento de escribir este libro ni siquiera estÃ¡n definidos en la legislaciÃ³n europea unos lÃ­mites mÃ¡ximos para el contenido de estos productos en los alimentos. Estaba previsto para 2014, pero se anunciÃ³ su retraso hasta 2021 (a partir del 1 de abril de este aÃ±o entra en vigor un lÃ­mite europeo para esas grasas trans de origen industrial). Esa regulaciÃ³n sÃ­ existe en algunos paÃ­ses europeos, como Dinamarca, donde los alimentos no pueden contener mÃ¡s de un 2% de grasas trans por cada 100 gramos de grasa. En EspaÃ±a seguimos esperando. Por el momento lo que sabemos es que, segÃºn un estudio publicado por el Ministerio de Sanidad en el aÃ±o 2015, el contenido medio de estas grasas en los alimentos era inferior al 2% con respecto a la grasa total, es decir, la cantidad no es muy elevada, pero serÃ­a deseable que fuera incluso menor., Las grasas hidrogenadas y las grasas trans ya no reciben tanta atenciÃ³n como antes, y es sobre todo porque cada vez se utilizan menos en la industria alimentaria debido a su mala fama. En su lugar, comenzaron a utilizarse otras opciones. La mÃ¡s inmediata fue el aceite de palma, que en poco tiempo se hizo omnipresente en la mayorÃ­a de los alimentos ultraprocesados, debido principalmente a su bajo coste y sus caracterÃ­sticas tecnolÃ³gicas. Se trata de un aceite que tiene una alta proporciÃ³n de Ã¡cidos grasos saturados, asÃ­ que aporta a los productos una buena textura y un aspecto adecuado, que se mantienen a lo largo del tiempo., El aceite de palma no cayÃ³ del cielo de repente, pero lo pareciÃ³. Ya se utilizaba en la formulaciÃ³n de muchos productos desde tiempo atrÃ¡s, pero no Ã©ramos conscientes de ello porque se declaraba en la lista de ingredientes como âgrasa vegetalâ. Esto cambiÃ³ a finales del aÃ±o 2014, cuando entrÃ³ en vigor el reglamento europeo que obliga a especificar el nombre de cada una de las grasas que contiene un producto, en lugar de declararlas de forma genÃ©rica. A partir de entonces comenzamos a encontrar el aceite de palma hasta en la sopa... Literalmente., La historia se repitiÃ³. En poco tiempo este aceite adquiriÃ³ muy mala fama. Fue debido sobre todo a dos motivos. Por un lado, se hablÃ³ mucho y mal de la forma en la que se obtiene la materia prima, que procede principalmente de Indonesia y Malasia, donde su explotaciÃ³n supone un enorme impacto ambiental y se realiza en unas condiciones laborales que dejan bastante que desear., Por otro, en un breve espacio de tiempo se sucedieron varias publicaciones que alertaban de los posibles efectos de este aceite sobre la salud. Entre ellas, un informe de la Autoridad Europea de Seguridad Alimentaria (EFSA) que advertÃ­a de la presencia de compuestos tÃ³xicos en el aceite de palma, derivados del calentamiento que se aplica en el proceso de obtenciÃ³n., TambiÃ©n se publicaron estudios que relacionaban uno de los componentes del aceite de palma con efectos adversos sobre la salud. Se trata del Ã¡cido palmÃ­tico, que precisamente recibe ese nombre porque es abundante en este tipo de aceite (se encuentra en una proporciÃ³n del 43 % aproximadamente). De todos modos, no estÃ¡ claro que este Ã¡cido graso sea tan malo como a veces se pinta. AdemÃ¡s, es uno de los mÃ¡s comunes y estÃ¡ presente de forma natural en infinidad de alimentos, como el aceite de oliva o la leche., La conclusiÃ³n que podemos extraer de todo esto es que el aceite de palma no es el mÃ¡s recomendable, especialmente en un entorno donde tenemos un aceite mucho mÃ¡s saludable, como el de oliva. Pero eso no significa que sea tÃ³xico o venenoso, como llegÃ³ a publicar algÃºn medio de comunicaciÃ³n. Lo cierto es que no estÃ¡ claro que su consumo tenga un efecto perjudicial sobre la salud, o al menos no tanto como muchas personas piensan. En cualquier caso, nuestra atenciÃ³n en este aspecto no deberÃ­a centrarse tanto sobre el aceite de palma y sus caracterÃ­sticas, sino mÃ¡s bien sobre los productos en los que se encuentra: galletas, pizzas, cruasanes, dÃ³nuts, etc., DespuÃ©s de la preocupaciÃ³n social que generÃ³ el aceite de palma en EspaÃ±a entre los aÃ±os 2016 y 2017, muchas empresas comenzaron a sustituirlo por otros tipos de grasa, como el aceite de coco, y a destacar en el envase la ausencia del temido ingrediente. En estos casos tambiÃ©n deberÃ­amos aplicar la mÃ¡xima de fijarnos en el conjunto del alimento en lugar de centrarnos en un ingrediente aislado., Miguel A. LurueÃ±a (@gominolasdpetro) es doctor, licenciado en ciencia y tecnologÃ­a de los alimentos, ingeniero tÃ©cnico agroalimentario y divulgador cientÃ­fico (www.gominolasdepetroleo.com)., NUTRIR CON CIENCIA es una secciÃ³n sobre alimentaciÃ³n basada en evidencias cientÃ­ficas y en el conocimiento contrastado por especialistas. Comer es mucho mÃ¡s que un placer y una necesidad: la dieta y los hÃ¡bitos alimenticios son ahora mismo el factor de salud pÃºblica que mÃ¡s puede ayudarnos a prevenir numerosas enfermedades, desde muchos tipos de cÃ¡ncer hasta la diabetes. Un equipo de dietistas-nutricionistas nos ayudarÃ¡ a conocer mejor la importancia de la alimentaciÃ³n y a derribar, gracias a la ciencia, los mitos que nos llevan a comer mal., Puedes seguir a Materia en Facebook, Twitter, Instagram o suscribirte aquÃ­ a nuestra newsletter']\n",
    "    array_documentos_query=tf_idf.unirArrays(array_query,array_documentos)\n",
    "    print(array_documentos_query)\n",
    "    #busco la posicion de mi query\n",
    "    posicion_query=tf_idf.calcularTF(array_documentos_query,array_query)\n",
    "    #obtengo el vector de documentos\n",
    "    vector_documentos=tf_idf.vectorTF_IDF(array_documentos_query)\n",
    "    #obtengo la similitud\n",
    "    similitud=tf_idf.similitudTF_IDF(vector_documentos,posicion_query)\n",
    "    print(similitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644f876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no encontrado, FALTA ARTICULO\n",
      "TITULO\n",
      "27\n",
      "ARTICULO\n",
      "27\n",
      "FECHAS\n",
      "27\n",
      "TITULO\n",
      "40\n",
      "ARTICULO\n",
      "40\n",
      "FECHAS\n",
      "40\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "no encontrado, FALTA ARTICULO\n",
      "TITULO\n",
      "30\n",
      "ARTICULO\n",
      "30\n",
      "FECHAS\n",
      "30\n",
      "['CataluÃ±a bate rÃ©cord de visitas por covid a ambulatorios con 73.000 en un dÃ­a', 'VÃ­ctimas del mar, la pobreza y el olvido', 'La baja de casi 2.500 profesionales sanitarios tensiona aÃºn mÃ¡s el sistema en CataluÃ±a', 'El debate sobre las cuarentenas en los colegios: Â¿Hay que confinar a toda la clase tras un positivo? ', 'La variante Paz Padilla ', 'El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'Los contagiados en la Comunidad Valenciana crecen en 32.659 casos en una semana pero solo hay cinco mÃ¡s en las UCI', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'CataluÃ±a habilita las farmacias para comunicar los positivos por covid para reducir presiÃ³n en los ambulatorios', 'La avalancha de contagios por la variante Ã³micron y el avance de la tercera dosis disparan la inmunidad entre la poblaciÃ³n', 'Ãmicron lleva al lÃ­mite a la atenciÃ³n primaria', 'Destellos de felicidad', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'El aÃ±o por delante', 'CataluÃ±a y Madrid acumulan miles de contagios sin notificar a Sanidad', 'Las zonas con mayor poder adquisitivo de Madrid sufren mayor tasa de contagios de covid', 'A ver si se acaba 2020 otra vez', 'Colas para recoger los test de antÃ­genos gratuitos en TorrejÃ³n de Ardoz y MÃ³stoles', 'Paremos la pandemia del lucro', 'La imparable ola de contagios de la ola Ã³micron obliga al Gobierno a dar un giro en la gestiÃ³n de la pandemia', 'El impacto de la sexta ola de covid en CataluÃ±a: âNo hay policÃ­as para Nochevieja, caemos como moscasâ', 'Los antÃ­genos de la especulaciÃ³n', 'Una Chevrolet 400, Marco Polo y una rifa, al auxilio de la Navidad de Juan Manuel', 'Ayuso, en su balance anual: âMadrid tiene la mejor sanidad de EspaÃ±aâ', 'La hidrocefalia pediÃ¡trica o cÃ³mo la falta de servicios de salud esenciales marca una vida', 'Navidad jubilosa']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['CataluÃ±a bate rÃ©cord de visitas por covid a ambulatorios con 73.000 en un dÃ­a', 'VÃ­ctimas del mar, la pobreza y el olvido', 'La baja de casi 2.500 profesionales sanitarios tensiona aÃºn mÃ¡s el sistema en CataluÃ±a', 'El debate sobre las cuarentenas en los colegios: Â¿Hay que confinar a toda la clase tras un positivo? ', 'La variante Paz Padilla ', 'El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'Los contagiados en la Comunidad Valenciana crecen en 32.659 casos en una semana pero solo hay cinco mÃ¡s en las UCI', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'CataluÃ±a habilita las farmacias para comunicar los positivos por covid para reducir presiÃ³n en los ambulatorios', 'La avalancha de contagios por la variante Ã³micron y el avance de la tercera dosis disparan la inmunidad entre la poblaciÃ³n', 'Ãmicron lleva al lÃ­mite a la atenciÃ³n primaria', 'Destellos de felicidad', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'El aÃ±o por delante', 'CataluÃ±a y Madrid acumulan miles de contagios sin notificar a Sanidad', 'Las zonas con mayor poder adquisitivo de Madrid sufren mayor tasa de contagios de covid', 'A ver si se acaba 2020 otra vez', 'Colas para recoger los test de antÃ­genos gratuitos en TorrejÃ³n de Ardoz y MÃ³stoles', 'Paremos la pandemia del lucro', 'La imparable ola de contagios de la ola Ã³micron obliga al Gobierno a dar un giro en la gestiÃ³n de la pandemia', 'El impacto de la sexta ola de covid en CataluÃ±a: âNo hay policÃ­as para Nochevieja, caemos como moscasâ', 'Los antÃ­genos de la especulaciÃ³n', 'Una Chevrolet 400, Marco Polo y una rifa, al auxilio de la Navidad de Juan Manuel', 'Ayuso, en su balance anual: âMadrid tiene la mejor sanidad de EspaÃ±aâ', 'La hidrocefalia pediÃ¡trica o cÃ³mo la falta de servicios de salud esenciales marca una vida', 'Navidad jubilosa']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n",
      "['El sistema inmune de vacunados y reinfectados resiste ante Ã³micron ', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'El oro: una historia de violencia cÃ³smica', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'La ciencia en el centro de la agenda', 'Â¿Somos polvo de estrellas?', 'El tomate no es natural, es un tesoro creado por el ingenio humano', 'La âfluronaâ no es nueva: le han puesto nombre ahora, pero ya se observÃ³ en EspaÃ±a al inicio de la pandemia', 'Â¿Por quÃ© nos obsesiona Marte?', 'Â¿Por quÃ© recordamos lo que ocurriÃ³ hace mucho tiempo y olvidamos lo que pasÃ³ ayer?', 'Ãmicron es el virus con la propagaciÃ³n mÃ¡s rÃ¡pida de la historia', 'âEspaÃ±a tendrÃ­a que vacunar a su sistema de salud, fortalecerlo para la fase endÃ©micaâ', 'Las organizaciones investigadoras que soliciten financiaciÃ³n europea tienen que contar con un plan viable de igualdad', 'Voracidad y optimizaciÃ³n', 'MÃ¡s mascarillas, clases semipresenciales y test continuos: Ã³micron altera la vuelta a las clases en todo el mundo', 'No serÃ¡ Leo DiCaprio quien nos avise del apocalipsis', 'La vuelta a clase serÃ¡ presencial: EducaciÃ³n reclamarÃ¡ a las comunidades mÃ¡s âtensiÃ³nâ en la aplicaciÃ³n del protocolo anticovid', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'El oro: una historia de violencia cÃ³smica', 'Jacques Tits, una vida consagrada al edificio de las matemÃ¡ticas', 'CÃ³mo el ataque de Pearl Harbor cambiÃ³ la estadÃ­stica de las pruebas diagnÃ³sticas', 'La teorÃ­a cuÃ¡ntica es mÃ¡s coherente de lo que creÃ­amos', 'Las matemÃ¡ticas de las mÃ¡quinas morales', 'Los renos de PapÃ¡ Noel', 'Teselaciones posibles e imposibles', 'Sin lÃ­neas de fractura', 'Lo que la ciencia debe a Steven Spielberg', 'Bach, Borges, Escher y la belleza fractal de la naturaleza', 'Los rayos X en los ojos que âcegaronâ a RamÃ³n y Cajal y Valle-InclÃ¡n', 'Los relatos mÃ©dicos de un poeta', 'La realidad completÃ¡ndose a sÃ­ misma', 'Â¿QuÃ© diÃ¡metro tiene el universo?', 'Â¿CÃ³mo se mide la altura de las montaÃ±as?', 'Como el fuego es un plasma, Â¿podrÃ­a usarse plasma de agua para apagarlo?', 'Â¿CuÃ¡nto dura la comida cocinada?', 'Invitados indeseables por Navidad: el muÃ©rdago y otras plagas que evitar durante las fiestas', 'Las âappsâ nutricionales o cÃ³mo comer bien no deberÃ­a depender de uno mismo', 'MalnutriciÃ³n invisible: el impacto de la pobreza en la salud infantil', 'El Ã³xido de etileno, la sustancia cancerÃ­gena que ha obligado a retirar miles de alimentos en la UE', 'Que no te lÃ­en con los ingredientes: aceites y grasas de mala calidad nutricional']\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "class R_Noticias(ttk.Frame):\n",
    "    \n",
    "    def __init__(self, main_window,sanidad,tecnologia,ciencia):\n",
    "        super().__init__(main_window)\n",
    "        self.grid()\n",
    "        #self.usuario= Usuario.__new__(Usuario)\n",
    "        self.create_widgets()\n",
    "        self.sanidad=sanidad\n",
    "        self.tecnologia=tecnologia\n",
    "        self.ciencia=ciencia\n",
    "        self.sort=[]\n",
    "        self.tema=''\n",
    "        self.usuario_sanidad=Usuario('','sanidad',5,self.sanidad)\n",
    "        self.usuario_tecnologia=Usuario('','tecnologia',5,self.tecnologia)\n",
    "        self.usuario_ciencia=Usuario('','ciencia',5,self.ciencia)\n",
    "        self.page=''\n",
    "        #self.data = Data(self.webPage)\n",
    "    def create_widgets(self):\n",
    "        \"\"\"this creates all the objects in the window\"\"\"\n",
    "\n",
    "        self.title_lbl = ttk.Label(self,text = \"Seleccionar Noticia de Referencia\").grid(column = 0, row = 0)\n",
    "        self.label = ttk.Label(self, text = \"Medio\").grid(column = 0,\n",
    "                                                      row = 1)\n",
    "        self.label1 = ttk.Label(self, text = \"Categoria\").grid(column = 1,\n",
    "                                                      row =1)\n",
    "        \n",
    "        self.label2 = ttk.Label(self, text = \"Noticias\").grid(column = 2,row = 1)\n",
    "        self.combovar = StringVar()\n",
    "        self.combovar1 = StringVar()\n",
    "        self.combovar2 = StringVar()\n",
    "        self.top_text = StringVar()\n",
    "        self.articulos_similitud = StringVar()\n",
    "        self.medio = ttk.Combobox(self,textvariable = self.combovar,state = 'readonly')\n",
    "        self.medio['values'] = ('Medio 1','Mi PaÃ­s','Medio 2')\n",
    "        self.medio.current(0)\n",
    "        self.medio.grid(column = 0, row = 2)\n",
    "        self.categoria = ttk.Combobox(self,textvariable = self.combovar1,state = 'readonly')\n",
    "        self.categoria['values'] = ('Sanidad','TecnologÃ­a','Ciencia')\n",
    "        #self.categoria.current(0)\n",
    "        self.categoria.grid(column = 1, row = 2)\n",
    "        self.noticias = ttk.Combobox(self,textvariable = self.combovar2,state = 'readonly')\n",
    "        self.noticias.grid(column = 2, row = 2)\n",
    "        self.categoria.bind(\"<<ComboboxSelected>>\", self.selection_changed)\n",
    "        self.entry_var = tk.StringVar()\n",
    "        self.noticias.bind(\"<<ComboboxSelected>>\", self.getArticulo)\n",
    "        self.text_area = scrolledtext.ScrolledText(self, wrap=tk.WORD, height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.text_area.grid(column=0,columnspan=8, row=3,rowspan=2, pady=10, padx=10)\n",
    "        self.label4 = ttk.Label(self, text = \"Top:\").grid(column = 0,\n",
    "                                                      row = 7)\n",
    "        self.top_items = ttk.Combobox(self,textvariable =  self.top_text,state = 'readonly')\n",
    "        self.top_items['values'] = (1,2,3,4,5)\n",
    "        self.top_items.current(4)\n",
    "        self.top_items.grid(column = 0, row = 8)\n",
    "        self.top_articulos = ttk.Combobox(self,state = 'readonly')\n",
    "        self.label4 = ttk.Label(self, text = \"Ranking:\").grid(column = 2,\n",
    "                                                      row = 7)\n",
    "        self.top_articulos.grid(column = 2, row = 8)\n",
    "        self.top=ttk.Button(self, text=\"Buscar\",command=self.getTop)\n",
    "        self.top.grid(row=8,column=1)\n",
    "        self.top_articulos.bind(\"<<ComboboxSelected>>\", self.getOtrosAtriculos)\n",
    "        self.otras_noticias = scrolledtext.ScrolledText(self, wrap=tk.WORD,height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.otras_noticias.grid(column=0,columnspan=8, row=10,rowspan=2, pady=10, padx=10)\n",
    "   \n",
    "    def selection_changed(self, event):\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            init_list=self.sanidad.getTitulo()\n",
    "            #print(self.sanidad.getTitulo())\n",
    "        elif self.categoria.get() == 'TecnologÃ­a':\n",
    "            init_list=self.tecnologia.getTitulo()\n",
    "            #print(self.ciencia.getTitulo())\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            init_list=self.ciencia.getTitulo()\n",
    "            #print(self.ciencia.getTitulo())\n",
    "        lista = [x for x in init_list]\n",
    "        self.noticias['values'] = lista\n",
    "        self.noticias.current(0)\n",
    "\n",
    "        \n",
    "    def getArticulo(self,event):\n",
    "        self.text_area.delete(1.0, END)\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            self.usuario_sanidad=Usuario(self.noticias.get(),'sanidad',5,self.sanidad)\n",
    "            self.usuario_sanidad.cargarSeleccion()\n",
    "            self.text_area.insert(END,str(self.sanidad.mostrarArticulo()))\n",
    "        elif self.categoria.get() == 'TecnologÃ­a':\n",
    "            self.usuario_tecnologia=Usuario(self.noticias.get(),'tecnologia',5,self.tecnologia)\n",
    "            self.usuario_tecnologia.cargarSeleccion()\n",
    "            self.text_area.insert(END,self.tecnologia.mostrarArticulo())\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            self.usuario_ciencia=Usuario(self.noticias.get(),'ciencia',5,self.ciencia)\n",
    "            self.usuario_ciencia.cargarSeleccion()\n",
    "            self.text_area.insert(END,self.ciencia.mostrarArticulo())\n",
    "    def getTop(self):\n",
    "        self.top_articulos.set('')\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            self.usuario_sanidad.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.sanidad.similitud(self.sanidad.other_etiquetas)\n",
    "            init_list=self.sanidad.similitudes\n",
    "        elif self.categoria.get() == 'TecnologÃ­a':\n",
    "            self.usuario_tecnologia.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.tecnologia.similitud(self.tecnologia.other_etiquetas)\n",
    "            init_list=self.tecnologia.similitudes\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            self.usuario_ciencia.setTop(int(self.top_items.get()))\n",
    "            self.sort=self.ciencia.similitud(self.ciencia.other_etiquetas)\n",
    "            init_list=self.ciencia.similitudes\n",
    "        \n",
    "        lista = [x for x in init_list]\n",
    "        self.top_articulos['values'] =lista\n",
    "        self.top_articulos.current(0)\n",
    "    def getOtrosAtriculos(self,event):\n",
    "        self.otras_noticias.delete(1.0, END)\n",
    "        if self.categoria.get() in 'Sanidad':\n",
    "            articulo= self.sanidad.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        elif self.categoria.get() == 'TecnologÃ­a':\n",
    "            articulo= self.tecnologia.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        elif self.categoria.get() == 'Ciencia':\n",
    "            articulo= self.ciencia.getSimilitud_Paginas(self.sort[self.top_articulos.current()])\n",
    "            self.otras_noticias.insert(END,articulo)\n",
    "        \n",
    "    \n",
    "         \n",
    "#sanidad\n",
    "sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "#tecnologia\n",
    "tecnologia=WebPages('tecnologia','https://elpais.com/tecnologia/')\n",
    "tecnologia.escritura(tecnologia.miPais_news_scraper(),'tecnologia.data.json')\n",
    "#ciencia\n",
    "ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "data_sanidad=Data(sanidad)\n",
    "data_ciencia=Data(ciencia)\n",
    "data_tecnologia=Data(tecnologia)\n",
    "data_sanidad.saveArticle()       \n",
    "data_sanidad.getEtiqueta()\n",
    "data_ciencia.saveArticle()       \n",
    "data_ciencia.getEtiqueta()\n",
    "data_tecnologia.saveArticle()       \n",
    "data_tecnologia.getEtiqueta()\n",
    "main_window = tk.Tk()\n",
    "recomendacion_n = R_Noticias(main_window,data_sanidad,data_tecnologia,data_ciencia)\n",
    "main_window.geometry(\"750x550\")\n",
    "main_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "class B_Noticias(ttk.Frame):\n",
    "    \n",
    "    def __init__(self, main_window):\n",
    "        super().__init__(main_window)\n",
    "        self.grid()\n",
    "        self.create_widgets()\n",
    "    def create_widgets(self):\n",
    "        \"\"\"this creates all the objects in the window\"\"\"\n",
    "\n",
    "        self.title_lbl = ttk.Label(self,text = \"Busqueda de Noticia\").grid(column = 0, row = 0)\n",
    "        self.label = ttk.Label(self, text = \"Consulta:\").grid(column = 0,\n",
    "                                                      row = 1,padx=10, pady=10)\n",
    "        self.entry = ttk.Entry(self,width=30)\n",
    "        self.entry.grid(column=1,row=1,padx=10, pady=10)\n",
    "        self.label1 = ttk.Label(self, text = \"Top:\").grid(column = 0,\n",
    "                                                      row = 3, pady=10, padx=10)\n",
    "        self.combovar = StringVar()\n",
    "        self.top_items = ttk.Combobox(self,textvariable = self.combovar,state = 'readonly')\n",
    "        self.top_items['values'] = (1,2,3,4,5)\n",
    "        self.top_items.current(4)\n",
    "        self.top_items.grid(column = 1, row = 3)\n",
    "        self.label2 = ttk.Label(self, text = \"Filtrar:\").grid(column = 2,\n",
    "                                                      row = 3)\n",
    "        self.combovar_medio = StringVar()\n",
    "        self.medio = ttk.Combobox(self,textvariable = self.combovar_medio,state = 'readonly')\n",
    "        self.medio['values'] = ('Todos','Medio 1','Mi pais','Medio 3')\n",
    "        self.medio.current(0)\n",
    "        self.medio.grid(column = 3, row = 3)\n",
    "        self.buscar=ttk.Button(self, text=\"Buscar\")\n",
    "        self.buscar.grid(row=3,column=4)\n",
    "        self.label3 = ttk.Label(self, text = \"Ranking:\").grid(column = 0,\n",
    "                                                      row = 4)\n",
    "        self.combovar_ranking = StringVar()\n",
    "        self.ranking = ttk.Combobox(self,textvariable = self.combovar_ranking,state = 'readonly')\n",
    "        self.ranking.grid(column = 0, row = 5)\n",
    "        self.label3 = ttk.Label(self, text = \"Texto de la noticia:\").grid(column = 1,\n",
    "                                                      row = 4)\n",
    "        self.noticia = scrolledtext.ScrolledText(self, wrap=tk.WORD,height=5,\n",
    "                                      font=(\"Times New Roman\", 15))\n",
    "        self.noticia.grid(column=1,columnspan=8, row=5,rowspan=2, pady=10, padx=10)\n",
    "\n",
    "        \n",
    "\n",
    "main_window = tk.Tk()\n",
    "recomendacion_n = B_Noticias(main_window)\n",
    "main_window.geometry(\"1000x700\")\n",
    "main_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2621844",
   "metadata": {},
   "source": [
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tkinter.messagebox import showinfo\n",
    "sanidad=WebPages('sanidad','https://elpais.com/noticias/sanidad/' )\n",
    "sanidad.escritura(sanidad.miPais_news_scraper(),'sanidad.data.json')\n",
    "data_sanidad=Data(sanidad)\n",
    "tecnologia=WebPages('tecnologia','https://elpais.com/tecnologia/')\n",
    "tecnologia.escritura(tecnologia.miPais_news_scraper(),'tecnologia.data.json')\n",
    "data_tecnologia=Data(tecnologia)\n",
    "ciencia=WebPages('ciencia','https://elpais.com/ciencia/' )\n",
    "ciencia.escritura(ciencia.miPais_news_scraper(),'ciencia.data.json')\n",
    "data_ciencia=Data(ciencia)\n",
    "# root window\n",
    "root = tk.Tk()\n",
    "root.geometry('300x120')\n",
    "root.title('Progressbar Demo')\n",
    "\n",
    "\n",
    "def update_progress_label(file):\n",
    "    return f\"Current Progress: {pb['value']}%\",\" files downloaded\",file\n",
    "\n",
    "\n",
    "def progress():\n",
    "    if pb['value'] < 100:\n",
    "        pb['value'] += 20\n",
    "        value_label['text'] = update_progress_label('')\n",
    "    else:\n",
    "        showinfo(message='The progress completed!')\n",
    "\n",
    "\n",
    "def stop():\n",
    "    pb.stop()\n",
    "    value_label['text'] = update_progress_label('stop')\n",
    "\n",
    "def cargando_sanidad():\n",
    "    data_sanidad.saveArticle()       \n",
    "    data_sanidad.getEtiqueta()\n",
    "    pb['value'] += 33.4\n",
    "    value_label['text'] = update_progress_label('/Sanidad')\n",
    "def cargando_ciencia():\n",
    "    data_ciencia.saveArticle()       \n",
    "    data_ciencia.getEtiqueta()\n",
    "    value_label['text'] = update_progress_label('/Ciencia')\n",
    "    pb['value'] += 33.33\n",
    "def cargando_tecnologia():\n",
    "    data_tecnologia.saveArticle()       \n",
    "    data_tecnologia.getEtiqueta()\n",
    "    value_label['text'] = update_progress_label('/Tecnologia')\n",
    "    pb['value'] += 33.33\n",
    "    if pb['value'] == 100:\n",
    "        showinfo(message='The progress completed!')\n",
    "    \n",
    "# progressbar\n",
    "pb = ttk.Progressbar(\n",
    "    root,\n",
    "    orient='horizontal',\n",
    "    mode='determinate',\n",
    "    length=280\n",
    ")\n",
    "# place the progressbar\n",
    "pb.grid(column=0, row=0, columnspan=2, padx=10, pady=20)\n",
    "\n",
    "# label\n",
    "value_label = ttk.Label(root, text=update_progress_label(''))\n",
    "value_label.grid(column=0, row=1, columnspan=2)\n",
    "\n",
    "# start button\n",
    "ciencia = ttk.Button(root,text='Download Ciencia',command=cargando_ciencia)\n",
    "ciencia.grid(column=0, row=2, padx=10, pady=10, sticky=tk.E)\n",
    "\n",
    "sanidad = ttk.Button(root,text='Download Sanidad',command=cargando_sanidad)\n",
    "sanidad.grid(column=1, row=2, padx=10, pady=10, sticky=tk.W)\n",
    "tecnologia = ttk.Button(root,text='Download Tecnologia',command=cargando_tecnologia)\n",
    "tecnologia.grid(column=2, row=2, padx=10, pady=10, sticky=tk.W)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc38a5",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "documentos = [\"The best Italian restaurant enjoy the best pasta.\",\"The best the best American restaurant.\", \"American restaurant enjoy the best hamburger.\",\n",
    "              \"Korean restaurant enjoy the best bibimbap\"] #Documents\n",
    "query = [\"The best the best American restaurant.\"] #Query\n",
    "#stopwords elimina las palabras frecuentes como: a, el, ella,etc.\n",
    "stopWords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stopWords)\n",
    "#print transformer\n",
    "\n",
    "vector_documentos = vectorizer.fit_transform(documentos).toarray()\n",
    "vector_query = vectorizer.transform(query).toarray()\n",
    "\n",
    "print ('Vector de documentos', vectorizer.vocabulary_)\n",
    "print('Vector de documentos en array:',vector_documentos)\n",
    "print ('Vector de query en array', vector_query)\n",
    "print('--------------------------------------------')\n",
    "#funcion del coseno se le introducen dos valores \n",
    "cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)\n",
    "i=0\n",
    "x=0\n",
    "for vector in vector_documentos:\n",
    "    print (vector)\n",
    "    for testV in vector_query:\n",
    "        if np.array_equal(vector,testV):\n",
    "            print(vector,'y',testV)\n",
    "            x=i\n",
    "        print (testV)\n",
    "        cosine = cx(vector, testV)\n",
    "        print (cosine)\n",
    "    i=i+1\n",
    "print('X ESTA EN LA POSICION',x)\n",
    "for testV in vector_query:\n",
    "    print ('a',testV)\n",
    "    cosine = similarity_scores = vector_documentos.dot(testV)/(np.linalg.norm(vector_documentos, axis=1) * np.linalg.norm(testV))\n",
    "print ('similitud en el documento N: ',cosine)\n",
    "\n",
    "print('--------------------------------------------')\n",
    "stop = list(stopwords.words('english'))\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',tokenizer=stemming_tokenizer,use_idf=True,norm='l2')\n",
    "tfidf_vectorizer2 = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
    "tfidf_query = tfidf_vectorizer2.fit_transform(query)\n",
    "#print ('QUERY',tfidf_query.toarray())\n",
    "print (tfidf_matrix.toarray())\n",
    "\n",
    "#print ('similitud en el documento N: ',cosine)\n",
    "#importante \n",
    "cosine = cosine_similarity(tfidf_matrix[x], tfidf_matrix)  #here the first element of tfidf_matrix_train is matched with other three elements\n",
    "print (cosine)\n",
    "\n",
    "\"\"\"\n",
    "transformer.fit(vector_documentos)\n",
    "print()\n",
    "print (transformer.transform(vector_documentos).toarray())\n",
    "\n",
    "transformer.fit(vector_query)\n",
    "print ()\n",
    "tfidf = transformer.transform(vector_query)\n",
    "print (tfidf.todense())\n",
    "for v in transformer.transform(vector_documentos).toarray():\n",
    "    for q in transformer.transform(vector_query).toarray():\n",
    "        cosine = cx(v, q)\n",
    "        print ('similitud en el documento N: ',cosine)\"\"\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
